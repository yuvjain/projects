{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNC9RB0Non0k"
      },
      "source": [
        "**Breast Cancer Classification with a simple Neural Network (NN)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WVsT2P6IdtX",
        "outputId": "f32a6a9e-febe-44bf-deb3-c7ee19001853"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.config.list_physical_devices('GPU')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GUR8W1Iowy3"
      },
      "source": [
        "Previous videos:\n",
        "\n",
        "\n",
        "*   Brest Cancer Classification with Logistic Regression video: https://youtu.be/bFh1umUDaGc\n",
        "*   EDA video: https://youtu.be/imdS1LIlISY\n",
        "*   Data Visualization video: https://youtu.be/gFSerq21wo8\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3wT8l6lfj--"
      },
      "source": [
        "**Importing the Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "XqsQmOXGXXTe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.datasets\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwJ9zLukg3Q_"
      },
      "source": [
        "Data Collection & Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "j6bMZMKUgz7L"
      },
      "outputs": [],
      "source": [
        "# loading the data from sklearn\n",
        "breast_cancer_dataset = sklearn.datasets.load_breast_cancer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdY6i73KgkDG",
        "outputId": "65dca706-b7ee-45d3-823d-cf740bb2c206"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
            "        1.189e-01],\n",
            "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
            "        8.902e-02],\n",
            "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
            "        8.758e-02],\n",
            "       ...,\n",
            "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
            "        7.820e-02],\n",
            "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
            "        1.240e-01],\n",
            "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
            "        7.039e-02]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
            "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
            "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
            "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
            "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
            "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
            "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
            "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
            "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
            "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
            "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
            "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
            "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
            "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), 'frame': None, 'target_names': array(['malignant', 'benign'], dtype='<U9'), 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n|details-start|\\n**References**\\n|details-split|\\n\\n- W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n  for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n  Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n  San Jose, CA, 1993.\\n- O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n  prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n  July-August 1995.\\n- W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n  to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n  163-171.\\n\\n|details-end|', 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
            "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
            "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
            "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
            "       'smoothness error', 'compactness error', 'concavity error',\n",
            "       'concave points error', 'symmetry error',\n",
            "       'fractal dimension error', 'worst radius', 'worst texture',\n",
            "       'worst perimeter', 'worst area', 'worst smoothness',\n",
            "       'worst compactness', 'worst concavity', 'worst concave points',\n",
            "       'worst symmetry', 'worst fractal dimension'], dtype='<U23'), 'filename': 'breast_cancer.csv', 'data_module': 'sklearn.datasets.data'}\n"
          ]
        }
      ],
      "source": [
        "print(breast_cancer_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "yFamhVTThMdK"
      },
      "outputs": [],
      "source": [
        "# loading the data to a data frame\n",
        "data_frame = pd.DataFrame(breast_cancer_dataset.data, columns = breast_cancer_dataset.feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "xLiv1maYiGVH",
        "outputId": "3f6ffcb5-6105-405a-8436-56a2133b4ba5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "0        17.99         10.38          122.80     1001.0          0.11840   \n",
              "1        20.57         17.77          132.90     1326.0          0.08474   \n",
              "2        19.69         21.25          130.00     1203.0          0.10960   \n",
              "3        11.42         20.38           77.58      386.1          0.14250   \n",
              "4        20.29         14.34          135.10     1297.0          0.10030   \n",
              "\n",
              "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "0           0.27760          0.3001              0.14710         0.2419   \n",
              "1           0.07864          0.0869              0.07017         0.1812   \n",
              "2           0.15990          0.1974              0.12790         0.2069   \n",
              "3           0.28390          0.2414              0.10520         0.2597   \n",
              "4           0.13280          0.1980              0.10430         0.1809   \n",
              "\n",
              "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
              "0                 0.07871  ...         25.38          17.33           184.60   \n",
              "1                 0.05667  ...         24.99          23.41           158.80   \n",
              "2                 0.05999  ...         23.57          25.53           152.50   \n",
              "3                 0.09744  ...         14.91          26.50            98.87   \n",
              "4                 0.05883  ...         22.54          16.67           152.20   \n",
              "\n",
              "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
              "0      2019.0            0.1622             0.6656           0.7119   \n",
              "1      1956.0            0.1238             0.1866           0.2416   \n",
              "2      1709.0            0.1444             0.4245           0.4504   \n",
              "3       567.7            0.2098             0.8663           0.6869   \n",
              "4      1575.0            0.1374             0.2050           0.4000   \n",
              "\n",
              "   worst concave points  worst symmetry  worst fractal dimension  \n",
              "0                0.2654          0.4601                  0.11890  \n",
              "1                0.1860          0.2750                  0.08902  \n",
              "2                0.2430          0.3613                  0.08758  \n",
              "3                0.2575          0.6638                  0.17300  \n",
              "4                0.1625          0.2364                  0.07678  \n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# print the first 5 rows of the dataframe\n",
        "data_frame.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "UEvD_aTDiNLF"
      },
      "outputs": [],
      "source": [
        "# adding the 'target' column to the data frame\n",
        "data_frame['label'] = breast_cancer_dataset.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "f_kmjEA5io2v",
        "outputId": "d4c5d3bc-c959-43ac-80b2-934e44d1f77d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>...</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>...</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>...</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>...</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>...</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "564        21.56         22.39          142.00     1479.0          0.11100   \n",
              "565        20.13         28.25          131.20     1261.0          0.09780   \n",
              "566        16.60         28.08          108.30      858.1          0.08455   \n",
              "567        20.60         29.33          140.10     1265.0          0.11780   \n",
              "568         7.76         24.54           47.92      181.0          0.05263   \n",
              "\n",
              "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "564           0.11590         0.24390              0.13890         0.1726   \n",
              "565           0.10340         0.14400              0.09791         0.1752   \n",
              "566           0.10230         0.09251              0.05302         0.1590   \n",
              "567           0.27700         0.35140              0.15200         0.2397   \n",
              "568           0.04362         0.00000              0.00000         0.1587   \n",
              "\n",
              "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
              "564                 0.05623  ...          26.40           166.10      2027.0   \n",
              "565                 0.05533  ...          38.25           155.00      1731.0   \n",
              "566                 0.05648  ...          34.12           126.70      1124.0   \n",
              "567                 0.07016  ...          39.42           184.60      1821.0   \n",
              "568                 0.05884  ...          30.37            59.16       268.6   \n",
              "\n",
              "     worst smoothness  worst compactness  worst concavity  \\\n",
              "564           0.14100            0.21130           0.4107   \n",
              "565           0.11660            0.19220           0.3215   \n",
              "566           0.11390            0.30940           0.3403   \n",
              "567           0.16500            0.86810           0.9387   \n",
              "568           0.08996            0.06444           0.0000   \n",
              "\n",
              "     worst concave points  worst symmetry  worst fractal dimension  label  \n",
              "564                0.2216          0.2060                  0.07115      0  \n",
              "565                0.1628          0.2572                  0.06637      0  \n",
              "566                0.1418          0.2218                  0.07820      0  \n",
              "567                0.2650          0.4087                  0.12400      0  \n",
              "568                0.0000          0.2871                  0.07039      1  \n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# print last 5 rows of the dataframe\n",
        "data_frame.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sw3wjdK6iwK4",
        "outputId": "f8ce35df-79eb-403f-e8b6-cbe588500fce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(569, 31)"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# number of rows and columns in the dataset\n",
        "data_frame.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWOjMuyBi77M",
        "outputId": "3b9ae8f3-eadd-4145-cf49-ed20b9adaa22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 31 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   mean radius              569 non-null    float64\n",
            " 1   mean texture             569 non-null    float64\n",
            " 2   mean perimeter           569 non-null    float64\n",
            " 3   mean area                569 non-null    float64\n",
            " 4   mean smoothness          569 non-null    float64\n",
            " 5   mean compactness         569 non-null    float64\n",
            " 6   mean concavity           569 non-null    float64\n",
            " 7   mean concave points      569 non-null    float64\n",
            " 8   mean symmetry            569 non-null    float64\n",
            " 9   mean fractal dimension   569 non-null    float64\n",
            " 10  radius error             569 non-null    float64\n",
            " 11  texture error            569 non-null    float64\n",
            " 12  perimeter error          569 non-null    float64\n",
            " 13  area error               569 non-null    float64\n",
            " 14  smoothness error         569 non-null    float64\n",
            " 15  compactness error        569 non-null    float64\n",
            " 16  concavity error          569 non-null    float64\n",
            " 17  concave points error     569 non-null    float64\n",
            " 18  symmetry error           569 non-null    float64\n",
            " 19  fractal dimension error  569 non-null    float64\n",
            " 20  worst radius             569 non-null    float64\n",
            " 21  worst texture            569 non-null    float64\n",
            " 22  worst perimeter          569 non-null    float64\n",
            " 23  worst area               569 non-null    float64\n",
            " 24  worst smoothness         569 non-null    float64\n",
            " 25  worst compactness        569 non-null    float64\n",
            " 26  worst concavity          569 non-null    float64\n",
            " 27  worst concave points     569 non-null    float64\n",
            " 28  worst symmetry           569 non-null    float64\n",
            " 29  worst fractal dimension  569 non-null    float64\n",
            " 30  label                    569 non-null    int64  \n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 137.9 KB\n"
          ]
        }
      ],
      "source": [
        "# getting some information about the data\n",
        "data_frame.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuoVIUTYjLpk",
        "outputId": "0b147579-0bf6-4145-b0ef-324da3d9a3bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "mean radius                0\n",
              "mean texture               0\n",
              "mean perimeter             0\n",
              "mean area                  0\n",
              "mean smoothness            0\n",
              "mean compactness           0\n",
              "mean concavity             0\n",
              "mean concave points        0\n",
              "mean symmetry              0\n",
              "mean fractal dimension     0\n",
              "radius error               0\n",
              "texture error              0\n",
              "perimeter error            0\n",
              "area error                 0\n",
              "smoothness error           0\n",
              "compactness error          0\n",
              "concavity error            0\n",
              "concave points error       0\n",
              "symmetry error             0\n",
              "fractal dimension error    0\n",
              "worst radius               0\n",
              "worst texture              0\n",
              "worst perimeter            0\n",
              "worst area                 0\n",
              "worst smoothness           0\n",
              "worst compactness          0\n",
              "worst concavity            0\n",
              "worst concave points       0\n",
              "worst symmetry             0\n",
              "worst fractal dimension    0\n",
              "label                      0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# checking for missing values\n",
        "data_frame.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "oLMuXI33jlkq",
        "outputId": "33c0c448-1313-4d16-831f-682bf5c4c8a5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>14.127292</td>\n",
              "      <td>19.289649</td>\n",
              "      <td>91.969033</td>\n",
              "      <td>654.889104</td>\n",
              "      <td>0.096360</td>\n",
              "      <td>0.104341</td>\n",
              "      <td>0.088799</td>\n",
              "      <td>0.048919</td>\n",
              "      <td>0.181162</td>\n",
              "      <td>0.062798</td>\n",
              "      <td>...</td>\n",
              "      <td>25.677223</td>\n",
              "      <td>107.261213</td>\n",
              "      <td>880.583128</td>\n",
              "      <td>0.132369</td>\n",
              "      <td>0.254265</td>\n",
              "      <td>0.272188</td>\n",
              "      <td>0.114606</td>\n",
              "      <td>0.290076</td>\n",
              "      <td>0.083946</td>\n",
              "      <td>0.627417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.524049</td>\n",
              "      <td>4.301036</td>\n",
              "      <td>24.298981</td>\n",
              "      <td>351.914129</td>\n",
              "      <td>0.014064</td>\n",
              "      <td>0.052813</td>\n",
              "      <td>0.079720</td>\n",
              "      <td>0.038803</td>\n",
              "      <td>0.027414</td>\n",
              "      <td>0.007060</td>\n",
              "      <td>...</td>\n",
              "      <td>6.146258</td>\n",
              "      <td>33.602542</td>\n",
              "      <td>569.356993</td>\n",
              "      <td>0.022832</td>\n",
              "      <td>0.157336</td>\n",
              "      <td>0.208624</td>\n",
              "      <td>0.065732</td>\n",
              "      <td>0.061867</td>\n",
              "      <td>0.018061</td>\n",
              "      <td>0.483918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>6.981000</td>\n",
              "      <td>9.710000</td>\n",
              "      <td>43.790000</td>\n",
              "      <td>143.500000</td>\n",
              "      <td>0.052630</td>\n",
              "      <td>0.019380</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106000</td>\n",
              "      <td>0.049960</td>\n",
              "      <td>...</td>\n",
              "      <td>12.020000</td>\n",
              "      <td>50.410000</td>\n",
              "      <td>185.200000</td>\n",
              "      <td>0.071170</td>\n",
              "      <td>0.027290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.055040</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>11.700000</td>\n",
              "      <td>16.170000</td>\n",
              "      <td>75.170000</td>\n",
              "      <td>420.300000</td>\n",
              "      <td>0.086370</td>\n",
              "      <td>0.064920</td>\n",
              "      <td>0.029560</td>\n",
              "      <td>0.020310</td>\n",
              "      <td>0.161900</td>\n",
              "      <td>0.057700</td>\n",
              "      <td>...</td>\n",
              "      <td>21.080000</td>\n",
              "      <td>84.110000</td>\n",
              "      <td>515.300000</td>\n",
              "      <td>0.116600</td>\n",
              "      <td>0.147200</td>\n",
              "      <td>0.114500</td>\n",
              "      <td>0.064930</td>\n",
              "      <td>0.250400</td>\n",
              "      <td>0.071460</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>13.370000</td>\n",
              "      <td>18.840000</td>\n",
              "      <td>86.240000</td>\n",
              "      <td>551.100000</td>\n",
              "      <td>0.095870</td>\n",
              "      <td>0.092630</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.033500</td>\n",
              "      <td>0.179200</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>...</td>\n",
              "      <td>25.410000</td>\n",
              "      <td>97.660000</td>\n",
              "      <td>686.500000</td>\n",
              "      <td>0.131300</td>\n",
              "      <td>0.211900</td>\n",
              "      <td>0.226700</td>\n",
              "      <td>0.099930</td>\n",
              "      <td>0.282200</td>\n",
              "      <td>0.080040</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>15.780000</td>\n",
              "      <td>21.800000</td>\n",
              "      <td>104.100000</td>\n",
              "      <td>782.700000</td>\n",
              "      <td>0.105300</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>0.130700</td>\n",
              "      <td>0.074000</td>\n",
              "      <td>0.195700</td>\n",
              "      <td>0.066120</td>\n",
              "      <td>...</td>\n",
              "      <td>29.720000</td>\n",
              "      <td>125.400000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>0.146000</td>\n",
              "      <td>0.339100</td>\n",
              "      <td>0.382900</td>\n",
              "      <td>0.161400</td>\n",
              "      <td>0.317900</td>\n",
              "      <td>0.092080</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>28.110000</td>\n",
              "      <td>39.280000</td>\n",
              "      <td>188.500000</td>\n",
              "      <td>2501.000000</td>\n",
              "      <td>0.163400</td>\n",
              "      <td>0.345400</td>\n",
              "      <td>0.426800</td>\n",
              "      <td>0.201200</td>\n",
              "      <td>0.304000</td>\n",
              "      <td>0.097440</td>\n",
              "      <td>...</td>\n",
              "      <td>49.540000</td>\n",
              "      <td>251.200000</td>\n",
              "      <td>4254.000000</td>\n",
              "      <td>0.222600</td>\n",
              "      <td>1.058000</td>\n",
              "      <td>1.252000</td>\n",
              "      <td>0.291000</td>\n",
              "      <td>0.663800</td>\n",
              "      <td>0.207500</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       mean radius  mean texture  mean perimeter    mean area  \\\n",
              "count   569.000000    569.000000      569.000000   569.000000   \n",
              "mean     14.127292     19.289649       91.969033   654.889104   \n",
              "std       3.524049      4.301036       24.298981   351.914129   \n",
              "min       6.981000      9.710000       43.790000   143.500000   \n",
              "25%      11.700000     16.170000       75.170000   420.300000   \n",
              "50%      13.370000     18.840000       86.240000   551.100000   \n",
              "75%      15.780000     21.800000      104.100000   782.700000   \n",
              "max      28.110000     39.280000      188.500000  2501.000000   \n",
              "\n",
              "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
              "count       569.000000        569.000000      569.000000           569.000000   \n",
              "mean          0.096360          0.104341        0.088799             0.048919   \n",
              "std           0.014064          0.052813        0.079720             0.038803   \n",
              "min           0.052630          0.019380        0.000000             0.000000   \n",
              "25%           0.086370          0.064920        0.029560             0.020310   \n",
              "50%           0.095870          0.092630        0.061540             0.033500   \n",
              "75%           0.105300          0.130400        0.130700             0.074000   \n",
              "max           0.163400          0.345400        0.426800             0.201200   \n",
              "\n",
              "       mean symmetry  mean fractal dimension  ...  worst texture  \\\n",
              "count     569.000000              569.000000  ...     569.000000   \n",
              "mean        0.181162                0.062798  ...      25.677223   \n",
              "std         0.027414                0.007060  ...       6.146258   \n",
              "min         0.106000                0.049960  ...      12.020000   \n",
              "25%         0.161900                0.057700  ...      21.080000   \n",
              "50%         0.179200                0.061540  ...      25.410000   \n",
              "75%         0.195700                0.066120  ...      29.720000   \n",
              "max         0.304000                0.097440  ...      49.540000   \n",
              "\n",
              "       worst perimeter   worst area  worst smoothness  worst compactness  \\\n",
              "count       569.000000   569.000000        569.000000         569.000000   \n",
              "mean        107.261213   880.583128          0.132369           0.254265   \n",
              "std          33.602542   569.356993          0.022832           0.157336   \n",
              "min          50.410000   185.200000          0.071170           0.027290   \n",
              "25%          84.110000   515.300000          0.116600           0.147200   \n",
              "50%          97.660000   686.500000          0.131300           0.211900   \n",
              "75%         125.400000  1084.000000          0.146000           0.339100   \n",
              "max         251.200000  4254.000000          0.222600           1.058000   \n",
              "\n",
              "       worst concavity  worst concave points  worst symmetry  \\\n",
              "count       569.000000            569.000000      569.000000   \n",
              "mean          0.272188              0.114606        0.290076   \n",
              "std           0.208624              0.065732        0.061867   \n",
              "min           0.000000              0.000000        0.156500   \n",
              "25%           0.114500              0.064930        0.250400   \n",
              "50%           0.226700              0.099930        0.282200   \n",
              "75%           0.382900              0.161400        0.317900   \n",
              "max           1.252000              0.291000        0.663800   \n",
              "\n",
              "       worst fractal dimension       label  \n",
              "count               569.000000  569.000000  \n",
              "mean                  0.083946    0.627417  \n",
              "std                   0.018061    0.483918  \n",
              "min                   0.055040    0.000000  \n",
              "25%                   0.071460    0.000000  \n",
              "50%                   0.080040    1.000000  \n",
              "75%                   0.092080    1.000000  \n",
              "max                   0.207500    1.000000  \n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# statistical measures about the data\n",
        "data_frame.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tC8Yii4Yjzer",
        "outputId": "4a06489d-cf17-4bfe-cde8-334328d5084f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "label\n",
              "1    357\n",
              "0    212\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# checking the distribution of Target Varibale\n",
        "data_frame['label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbbkzWeFkjqc"
      },
      "source": [
        "1 --> Benign\n",
        "\n",
        "0 --> Malignant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "YGWHjrVSkN5c",
        "outputId": "41329fa8-c22a-43f5-eb9c-c26f28b67014"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.462830</td>\n",
              "      <td>21.604906</td>\n",
              "      <td>115.365377</td>\n",
              "      <td>978.376415</td>\n",
              "      <td>0.102898</td>\n",
              "      <td>0.145188</td>\n",
              "      <td>0.160775</td>\n",
              "      <td>0.087990</td>\n",
              "      <td>0.192909</td>\n",
              "      <td>0.062680</td>\n",
              "      <td>...</td>\n",
              "      <td>21.134811</td>\n",
              "      <td>29.318208</td>\n",
              "      <td>141.370330</td>\n",
              "      <td>1422.286321</td>\n",
              "      <td>0.144845</td>\n",
              "      <td>0.374824</td>\n",
              "      <td>0.450606</td>\n",
              "      <td>0.182237</td>\n",
              "      <td>0.323468</td>\n",
              "      <td>0.091530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12.146524</td>\n",
              "      <td>17.914762</td>\n",
              "      <td>78.075406</td>\n",
              "      <td>462.790196</td>\n",
              "      <td>0.092478</td>\n",
              "      <td>0.080085</td>\n",
              "      <td>0.046058</td>\n",
              "      <td>0.025717</td>\n",
              "      <td>0.174186</td>\n",
              "      <td>0.062867</td>\n",
              "      <td>...</td>\n",
              "      <td>13.379801</td>\n",
              "      <td>23.515070</td>\n",
              "      <td>87.005938</td>\n",
              "      <td>558.899440</td>\n",
              "      <td>0.124959</td>\n",
              "      <td>0.182673</td>\n",
              "      <td>0.166238</td>\n",
              "      <td>0.074444</td>\n",
              "      <td>0.270246</td>\n",
              "      <td>0.079442</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       mean radius  mean texture  mean perimeter   mean area  mean smoothness  \\\n",
              "label                                                                           \n",
              "0        17.462830     21.604906      115.365377  978.376415         0.102898   \n",
              "1        12.146524     17.914762       78.075406  462.790196         0.092478   \n",
              "\n",
              "       mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "label                                                                         \n",
              "0              0.145188        0.160775             0.087990       0.192909   \n",
              "1              0.080085        0.046058             0.025717       0.174186   \n",
              "\n",
              "       mean fractal dimension  ...  worst radius  worst texture  \\\n",
              "label                          ...                                \n",
              "0                    0.062680  ...     21.134811      29.318208   \n",
              "1                    0.062867  ...     13.379801      23.515070   \n",
              "\n",
              "       worst perimeter   worst area  worst smoothness  worst compactness  \\\n",
              "label                                                                      \n",
              "0           141.370330  1422.286321          0.144845           0.374824   \n",
              "1            87.005938   558.899440          0.124959           0.182673   \n",
              "\n",
              "       worst concavity  worst concave points  worst symmetry  \\\n",
              "label                                                          \n",
              "0             0.450606              0.182237        0.323468   \n",
              "1             0.166238              0.074444        0.270246   \n",
              "\n",
              "       worst fractal dimension  \n",
              "label                           \n",
              "0                     0.091530  \n",
              "1                     0.079442  \n",
              "\n",
              "[2 rows x 30 columns]"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_frame.groupby('label').mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUPYps4DlVFR"
      },
      "source": [
        "Separating the features and target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "Z5pD8rP5kzKD"
      },
      "outputs": [],
      "source": [
        "X = data_frame.drop(columns='label', axis=1)\n",
        "Y = data_frame['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-GWJHpAlpWJ",
        "outputId": "b7aeab33-1427-46af-a6ba-c74f061c5b8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
            "0          17.99         10.38          122.80     1001.0          0.11840   \n",
            "1          20.57         17.77          132.90     1326.0          0.08474   \n",
            "2          19.69         21.25          130.00     1203.0          0.10960   \n",
            "3          11.42         20.38           77.58      386.1          0.14250   \n",
            "4          20.29         14.34          135.10     1297.0          0.10030   \n",
            "..           ...           ...             ...        ...              ...   \n",
            "564        21.56         22.39          142.00     1479.0          0.11100   \n",
            "565        20.13         28.25          131.20     1261.0          0.09780   \n",
            "566        16.60         28.08          108.30      858.1          0.08455   \n",
            "567        20.60         29.33          140.10     1265.0          0.11780   \n",
            "568         7.76         24.54           47.92      181.0          0.05263   \n",
            "\n",
            "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
            "0             0.27760         0.30010              0.14710         0.2419   \n",
            "1             0.07864         0.08690              0.07017         0.1812   \n",
            "2             0.15990         0.19740              0.12790         0.2069   \n",
            "3             0.28390         0.24140              0.10520         0.2597   \n",
            "4             0.13280         0.19800              0.10430         0.1809   \n",
            "..                ...             ...                  ...            ...   \n",
            "564           0.11590         0.24390              0.13890         0.1726   \n",
            "565           0.10340         0.14400              0.09791         0.1752   \n",
            "566           0.10230         0.09251              0.05302         0.1590   \n",
            "567           0.27700         0.35140              0.15200         0.2397   \n",
            "568           0.04362         0.00000              0.00000         0.1587   \n",
            "\n",
            "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
            "0                   0.07871  ...        25.380          17.33   \n",
            "1                   0.05667  ...        24.990          23.41   \n",
            "2                   0.05999  ...        23.570          25.53   \n",
            "3                   0.09744  ...        14.910          26.50   \n",
            "4                   0.05883  ...        22.540          16.67   \n",
            "..                      ...  ...           ...            ...   \n",
            "564                 0.05623  ...        25.450          26.40   \n",
            "565                 0.05533  ...        23.690          38.25   \n",
            "566                 0.05648  ...        18.980          34.12   \n",
            "567                 0.07016  ...        25.740          39.42   \n",
            "568                 0.05884  ...         9.456          30.37   \n",
            "\n",
            "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
            "0             184.60      2019.0           0.16220            0.66560   \n",
            "1             158.80      1956.0           0.12380            0.18660   \n",
            "2             152.50      1709.0           0.14440            0.42450   \n",
            "3              98.87       567.7           0.20980            0.86630   \n",
            "4             152.20      1575.0           0.13740            0.20500   \n",
            "..               ...         ...               ...                ...   \n",
            "564           166.10      2027.0           0.14100            0.21130   \n",
            "565           155.00      1731.0           0.11660            0.19220   \n",
            "566           126.70      1124.0           0.11390            0.30940   \n",
            "567           184.60      1821.0           0.16500            0.86810   \n",
            "568            59.16       268.6           0.08996            0.06444   \n",
            "\n",
            "     worst concavity  worst concave points  worst symmetry  \\\n",
            "0             0.7119                0.2654          0.4601   \n",
            "1             0.2416                0.1860          0.2750   \n",
            "2             0.4504                0.2430          0.3613   \n",
            "3             0.6869                0.2575          0.6638   \n",
            "4             0.4000                0.1625          0.2364   \n",
            "..               ...                   ...             ...   \n",
            "564           0.4107                0.2216          0.2060   \n",
            "565           0.3215                0.1628          0.2572   \n",
            "566           0.3403                0.1418          0.2218   \n",
            "567           0.9387                0.2650          0.4087   \n",
            "568           0.0000                0.0000          0.2871   \n",
            "\n",
            "     worst fractal dimension  \n",
            "0                    0.11890  \n",
            "1                    0.08902  \n",
            "2                    0.08758  \n",
            "3                    0.17300  \n",
            "4                    0.07678  \n",
            "..                       ...  \n",
            "564                  0.07115  \n",
            "565                  0.06637  \n",
            "566                  0.07820  \n",
            "567                  0.12400  \n",
            "568                  0.07039  \n",
            "\n",
            "[569 rows x 30 columns]\n"
          ]
        }
      ],
      "source": [
        "print(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5rs8pColqsn",
        "outputId": "49566743-7211-49c3-c24f-a5c3a0683eae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0      0\n",
            "1      0\n",
            "2      0\n",
            "3      0\n",
            "4      0\n",
            "      ..\n",
            "564    0\n",
            "565    0\n",
            "566    0\n",
            "567    0\n",
            "568    1\n",
            "Name: label, Length: 569, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5yk9d-Nl4VV"
      },
      "source": [
        "Splitting the data into training data & Testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "vZtU30bPluG_"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWaeuX3amqYH",
        "outputId": "6bb92b9b-b7e3-4495-b188-af3c8f6cc510"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(569, 30) (455, 30) (114, 30)\n"
          ]
        }
      ],
      "source": [
        "print(X.shape, X_train.shape, X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0g1NEndK7UB6"
      },
      "source": [
        "Standardize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "C5EP9f_B7UXU"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "sCGC8dku7cge"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "\n",
        "X_test_std = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxyxgeK8qkDj"
      },
      "source": [
        "**Building the Neural Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sC4KsFDyqyvN"
      },
      "source": [
        "![download.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "1WX_ChHfqrV2"
      },
      "outputs": [],
      "source": [
        "# importing tensorflow and Keras\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(3)\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "rL0jvBLY3Lkq"
      },
      "outputs": [],
      "source": [
        "# setting up the layers of Neural Network\n",
        "\n",
        "model = keras.Sequential([\n",
        "                          keras.layers.Flatten(input_shape=(30,)),\n",
        "                          keras.layers.Dense(20, activation='relu'),\n",
        "                          keras.layers.Dense(2, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "DrqX3ZGv48Ef"
      },
      "outputs": [],
      "source": [
        "# compiling the Neural Network\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4aullV3v584B",
        "outputId": "2611b3af-cab0-4179-92b5-4a5e408b0876"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "13/13 [==============================] - 1s 18ms/step - loss: 1.6367 - accuracy: 0.1687 - val_loss: 1.2993 - val_accuracy: 0.2609\n",
            "Epoch 2/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.2263 - accuracy: 0.3032 - val_loss: 0.9561 - val_accuracy: 0.3261\n",
            "Epoch 3/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.9284 - accuracy: 0.4425 - val_loss: 0.7068 - val_accuracy: 0.5217\n",
            "Epoch 4/1000\n",
            " 1/13 [=>............................] - ETA: 0s - loss: 0.8789 - accuracy: 0.4375"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13/13 [==============================] - 0s 9ms/step - loss: 0.7112 - accuracy: 0.6161 - val_loss: 0.5270 - val_accuracy: 0.7609\n",
            "Epoch 5/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5501 - accuracy: 0.7873 - val_loss: 0.4000 - val_accuracy: 0.8478\n",
            "Epoch 6/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.4255 - accuracy: 0.8606 - val_loss: 0.3195 - val_accuracy: 0.9348\n",
            "Epoch 7/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.3373 - accuracy: 0.9022 - val_loss: 0.2659 - val_accuracy: 0.9565\n",
            "Epoch 8/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.2767 - accuracy: 0.9169 - val_loss: 0.2289 - val_accuracy: 0.9565\n",
            "Epoch 9/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.2354 - accuracy: 0.9315 - val_loss: 0.2024 - val_accuracy: 0.9565\n",
            "Epoch 10/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.2049 - accuracy: 0.9315 - val_loss: 0.1836 - val_accuracy: 0.9565\n",
            "Epoch 11/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.1845 - accuracy: 0.9389 - val_loss: 0.1689 - val_accuracy: 0.9565\n",
            "Epoch 12/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1671 - accuracy: 0.9389 - val_loss: 0.1572 - val_accuracy: 0.9565\n",
            "Epoch 13/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1531 - accuracy: 0.9438 - val_loss: 0.1480 - val_accuracy: 0.9565\n",
            "Epoch 14/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1420 - accuracy: 0.9487 - val_loss: 0.1399 - val_accuracy: 0.9565\n",
            "Epoch 15/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1325 - accuracy: 0.9609 - val_loss: 0.1330 - val_accuracy: 0.9565\n",
            "Epoch 16/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1242 - accuracy: 0.9658 - val_loss: 0.1277 - val_accuracy: 0.9565\n",
            "Epoch 17/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1171 - accuracy: 0.9658 - val_loss: 0.1227 - val_accuracy: 0.9565\n",
            "Epoch 18/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1106 - accuracy: 0.9707 - val_loss: 0.1181 - val_accuracy: 0.9565\n",
            "Epoch 19/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1053 - accuracy: 0.9780 - val_loss: 0.1136 - val_accuracy: 0.9783\n",
            "Epoch 20/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1000 - accuracy: 0.9804 - val_loss: 0.1105 - val_accuracy: 0.9783\n",
            "Epoch 21/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0957 - accuracy: 0.9804 - val_loss: 0.1076 - val_accuracy: 0.9783\n",
            "Epoch 22/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0918 - accuracy: 0.9804 - val_loss: 0.1051 - val_accuracy: 0.9783\n",
            "Epoch 23/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0880 - accuracy: 0.9804 - val_loss: 0.1027 - val_accuracy: 0.9783\n",
            "Epoch 24/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0848 - accuracy: 0.9804 - val_loss: 0.1013 - val_accuracy: 0.9783\n",
            "Epoch 25/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0819 - accuracy: 0.9780 - val_loss: 0.0989 - val_accuracy: 0.9783\n",
            "Epoch 26/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0790 - accuracy: 0.9804 - val_loss: 0.0973 - val_accuracy: 0.9783\n",
            "Epoch 27/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0765 - accuracy: 0.9853 - val_loss: 0.0957 - val_accuracy: 0.9783\n",
            "Epoch 28/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0743 - accuracy: 0.9878 - val_loss: 0.0943 - val_accuracy: 0.9783\n",
            "Epoch 29/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0721 - accuracy: 0.9878 - val_loss: 0.0930 - val_accuracy: 0.9783\n",
            "Epoch 30/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0701 - accuracy: 0.9878 - val_loss: 0.0915 - val_accuracy: 0.9783\n",
            "Epoch 31/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0682 - accuracy: 0.9878 - val_loss: 0.0907 - val_accuracy: 0.9783\n",
            "Epoch 32/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0666 - accuracy: 0.9878 - val_loss: 0.0896 - val_accuracy: 0.9783\n",
            "Epoch 33/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0651 - accuracy: 0.9878 - val_loss: 0.0888 - val_accuracy: 0.9783\n",
            "Epoch 34/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0636 - accuracy: 0.9878 - val_loss: 0.0879 - val_accuracy: 0.9783\n",
            "Epoch 35/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0623 - accuracy: 0.9878 - val_loss: 0.0876 - val_accuracy: 0.9783\n",
            "Epoch 36/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0609 - accuracy: 0.9878 - val_loss: 0.0864 - val_accuracy: 0.9783\n",
            "Epoch 37/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0597 - accuracy: 0.9878 - val_loss: 0.0857 - val_accuracy: 0.9783\n",
            "Epoch 38/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0586 - accuracy: 0.9878 - val_loss: 0.0852 - val_accuracy: 0.9565\n",
            "Epoch 39/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0573 - accuracy: 0.9878 - val_loss: 0.0846 - val_accuracy: 0.9565\n",
            "Epoch 40/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0563 - accuracy: 0.9878 - val_loss: 0.0838 - val_accuracy: 0.9565\n",
            "Epoch 41/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0554 - accuracy: 0.9878 - val_loss: 0.0832 - val_accuracy: 0.9565\n",
            "Epoch 42/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0545 - accuracy: 0.9878 - val_loss: 0.0828 - val_accuracy: 0.9565\n",
            "Epoch 43/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0535 - accuracy: 0.9878 - val_loss: 0.0822 - val_accuracy: 0.9565\n",
            "Epoch 44/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0526 - accuracy: 0.9878 - val_loss: 0.0811 - val_accuracy: 0.9565\n",
            "Epoch 45/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0517 - accuracy: 0.9878 - val_loss: 0.0805 - val_accuracy: 0.9565\n",
            "Epoch 46/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0510 - accuracy: 0.9878 - val_loss: 0.0804 - val_accuracy: 0.9565\n",
            "Epoch 47/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0502 - accuracy: 0.9878 - val_loss: 0.0800 - val_accuracy: 0.9565\n",
            "Epoch 48/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0493 - accuracy: 0.9878 - val_loss: 0.0797 - val_accuracy: 0.9565\n",
            "Epoch 49/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0486 - accuracy: 0.9878 - val_loss: 0.0792 - val_accuracy: 0.9565\n",
            "Epoch 50/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0478 - accuracy: 0.9878 - val_loss: 0.0788 - val_accuracy: 0.9565\n",
            "Epoch 51/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0473 - accuracy: 0.9878 - val_loss: 0.0784 - val_accuracy: 0.9565\n",
            "Epoch 52/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0465 - accuracy: 0.9878 - val_loss: 0.0786 - val_accuracy: 0.9565\n",
            "Epoch 53/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0457 - accuracy: 0.9902 - val_loss: 0.0780 - val_accuracy: 0.9565\n",
            "Epoch 54/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0451 - accuracy: 0.9902 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
            "Epoch 55/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0445 - accuracy: 0.9902 - val_loss: 0.0772 - val_accuracy: 0.9565\n",
            "Epoch 56/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0439 - accuracy: 0.9902 - val_loss: 0.0778 - val_accuracy: 0.9565\n",
            "Epoch 57/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0432 - accuracy: 0.9902 - val_loss: 0.0774 - val_accuracy: 0.9565\n",
            "Epoch 58/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0428 - accuracy: 0.9902 - val_loss: 0.0770 - val_accuracy: 0.9565\n",
            "Epoch 59/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0420 - accuracy: 0.9902 - val_loss: 0.0770 - val_accuracy: 0.9565\n",
            "Epoch 60/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0415 - accuracy: 0.9902 - val_loss: 0.0763 - val_accuracy: 0.9565\n",
            "Epoch 61/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0409 - accuracy: 0.9902 - val_loss: 0.0763 - val_accuracy: 0.9565\n",
            "Epoch 62/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0404 - accuracy: 0.9902 - val_loss: 0.0767 - val_accuracy: 0.9565\n",
            "Epoch 63/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0399 - accuracy: 0.9902 - val_loss: 0.0761 - val_accuracy: 0.9565\n",
            "Epoch 64/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0393 - accuracy: 0.9902 - val_loss: 0.0762 - val_accuracy: 0.9565\n",
            "Epoch 65/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0389 - accuracy: 0.9902 - val_loss: 0.0761 - val_accuracy: 0.9565\n",
            "Epoch 66/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0383 - accuracy: 0.9902 - val_loss: 0.0760 - val_accuracy: 0.9565\n",
            "Epoch 67/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0378 - accuracy: 0.9902 - val_loss: 0.0762 - val_accuracy: 0.9565\n",
            "Epoch 68/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0374 - accuracy: 0.9902 - val_loss: 0.0774 - val_accuracy: 0.9565\n",
            "Epoch 69/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0369 - accuracy: 0.9902 - val_loss: 0.0782 - val_accuracy: 0.9565\n",
            "Epoch 70/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0364 - accuracy: 0.9902 - val_loss: 0.0766 - val_accuracy: 0.9565\n",
            "Epoch 71/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0360 - accuracy: 0.9902 - val_loss: 0.0758 - val_accuracy: 0.9565\n",
            "Epoch 72/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0355 - accuracy: 0.9902 - val_loss: 0.0766 - val_accuracy: 0.9565\n",
            "Epoch 73/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0349 - accuracy: 0.9902 - val_loss: 0.0770 - val_accuracy: 0.9565\n",
            "Epoch 74/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0345 - accuracy: 0.9902 - val_loss: 0.0764 - val_accuracy: 0.9565\n",
            "Epoch 75/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0340 - accuracy: 0.9902 - val_loss: 0.0769 - val_accuracy: 0.9565\n",
            "Epoch 76/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0336 - accuracy: 0.9902 - val_loss: 0.0771 - val_accuracy: 0.9565\n",
            "Epoch 77/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0332 - accuracy: 0.9902 - val_loss: 0.0773 - val_accuracy: 0.9565\n",
            "Epoch 78/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0329 - accuracy: 0.9902 - val_loss: 0.0774 - val_accuracy: 0.9565\n",
            "Epoch 79/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0323 - accuracy: 0.9902 - val_loss: 0.0776 - val_accuracy: 0.9565\n",
            "Epoch 80/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0320 - accuracy: 0.9902 - val_loss: 0.0778 - val_accuracy: 0.9565\n",
            "Epoch 81/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0318 - accuracy: 0.9902 - val_loss: 0.0774 - val_accuracy: 0.9565\n",
            "Epoch 82/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0312 - accuracy: 0.9902 - val_loss: 0.0780 - val_accuracy: 0.9565\n",
            "Epoch 83/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0308 - accuracy: 0.9902 - val_loss: 0.0777 - val_accuracy: 0.9565\n",
            "Epoch 84/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0304 - accuracy: 0.9902 - val_loss: 0.0778 - val_accuracy: 0.9565\n",
            "Epoch 85/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0301 - accuracy: 0.9902 - val_loss: 0.0779 - val_accuracy: 0.9565\n",
            "Epoch 86/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0298 - accuracy: 0.9902 - val_loss: 0.0774 - val_accuracy: 0.9565\n",
            "Epoch 87/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0293 - accuracy: 0.9902 - val_loss: 0.0782 - val_accuracy: 0.9565\n",
            "Epoch 88/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0291 - accuracy: 0.9902 - val_loss: 0.0782 - val_accuracy: 0.9565\n",
            "Epoch 89/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0287 - accuracy: 0.9902 - val_loss: 0.0777 - val_accuracy: 0.9565\n",
            "Epoch 90/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0284 - accuracy: 0.9902 - val_loss: 0.0783 - val_accuracy: 0.9565\n",
            "Epoch 91/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0281 - accuracy: 0.9927 - val_loss: 0.0786 - val_accuracy: 0.9565\n",
            "Epoch 92/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0277 - accuracy: 0.9927 - val_loss: 0.0783 - val_accuracy: 0.9565\n",
            "Epoch 93/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0274 - accuracy: 0.9927 - val_loss: 0.0785 - val_accuracy: 0.9565\n",
            "Epoch 94/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0271 - accuracy: 0.9902 - val_loss: 0.0778 - val_accuracy: 0.9565\n",
            "Epoch 95/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0268 - accuracy: 0.9902 - val_loss: 0.0776 - val_accuracy: 0.9565\n",
            "Epoch 96/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0265 - accuracy: 0.9927 - val_loss: 0.0782 - val_accuracy: 0.9565\n",
            "Epoch 97/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0261 - accuracy: 0.9927 - val_loss: 0.0777 - val_accuracy: 0.9565\n",
            "Epoch 98/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0260 - accuracy: 0.9927 - val_loss: 0.0777 - val_accuracy: 0.9565\n",
            "Epoch 99/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0255 - accuracy: 0.9927 - val_loss: 0.0775 - val_accuracy: 0.9565\n",
            "Epoch 100/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0253 - accuracy: 0.9927 - val_loss: 0.0765 - val_accuracy: 0.9565\n",
            "Epoch 101/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0250 - accuracy: 0.9927 - val_loss: 0.0769 - val_accuracy: 0.9565\n",
            "Epoch 102/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0248 - accuracy: 0.9927 - val_loss: 0.0766 - val_accuracy: 0.9565\n",
            "Epoch 103/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0245 - accuracy: 0.9927 - val_loss: 0.0762 - val_accuracy: 0.9565\n",
            "Epoch 104/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0242 - accuracy: 0.9951 - val_loss: 0.0760 - val_accuracy: 0.9565\n",
            "Epoch 105/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0239 - accuracy: 0.9951 - val_loss: 0.0765 - val_accuracy: 0.9565\n",
            "Epoch 106/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0237 - accuracy: 0.9951 - val_loss: 0.0762 - val_accuracy: 0.9565\n",
            "Epoch 107/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0235 - accuracy: 0.9951 - val_loss: 0.0765 - val_accuracy: 0.9565\n",
            "Epoch 108/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0233 - accuracy: 0.9951 - val_loss: 0.0743 - val_accuracy: 0.9565\n",
            "Epoch 109/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0229 - accuracy: 0.9951 - val_loss: 0.0753 - val_accuracy: 0.9565\n",
            "Epoch 110/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0227 - accuracy: 0.9951 - val_loss: 0.0759 - val_accuracy: 0.9565\n",
            "Epoch 111/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0225 - accuracy: 0.9951 - val_loss: 0.0753 - val_accuracy: 0.9565\n",
            "Epoch 112/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0221 - accuracy: 0.9951 - val_loss: 0.0745 - val_accuracy: 0.9565\n",
            "Epoch 113/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0220 - accuracy: 0.9951 - val_loss: 0.0743 - val_accuracy: 0.9565\n",
            "Epoch 114/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0217 - accuracy: 0.9951 - val_loss: 0.0739 - val_accuracy: 0.9565\n",
            "Epoch 115/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0214 - accuracy: 0.9951 - val_loss: 0.0740 - val_accuracy: 0.9565\n",
            "Epoch 116/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0212 - accuracy: 0.9951 - val_loss: 0.0738 - val_accuracy: 0.9565\n",
            "Epoch 117/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0210 - accuracy: 0.9951 - val_loss: 0.0745 - val_accuracy: 0.9565\n",
            "Epoch 118/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0207 - accuracy: 0.9951 - val_loss: 0.0740 - val_accuracy: 0.9565\n",
            "Epoch 119/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0205 - accuracy: 0.9951 - val_loss: 0.0733 - val_accuracy: 0.9565\n",
            "Epoch 120/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0202 - accuracy: 0.9951 - val_loss: 0.0734 - val_accuracy: 0.9565\n",
            "Epoch 121/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0201 - accuracy: 0.9951 - val_loss: 0.0734 - val_accuracy: 0.9565\n",
            "Epoch 122/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0198 - accuracy: 0.9951 - val_loss: 0.0729 - val_accuracy: 0.9565\n",
            "Epoch 123/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0196 - accuracy: 0.9951 - val_loss: 0.0731 - val_accuracy: 0.9565\n",
            "Epoch 124/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0194 - accuracy: 0.9951 - val_loss: 0.0728 - val_accuracy: 0.9565\n",
            "Epoch 125/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0192 - accuracy: 0.9951 - val_loss: 0.0729 - val_accuracy: 0.9565\n",
            "Epoch 126/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0191 - accuracy: 0.9951 - val_loss: 0.0724 - val_accuracy: 0.9565\n",
            "Epoch 127/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0188 - accuracy: 0.9951 - val_loss: 0.0723 - val_accuracy: 0.9565\n",
            "Epoch 128/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0186 - accuracy: 0.9951 - val_loss: 0.0720 - val_accuracy: 0.9565\n",
            "Epoch 129/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0184 - accuracy: 0.9951 - val_loss: 0.0719 - val_accuracy: 0.9565\n",
            "Epoch 130/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0183 - accuracy: 0.9951 - val_loss: 0.0726 - val_accuracy: 0.9565\n",
            "Epoch 131/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0180 - accuracy: 0.9951 - val_loss: 0.0724 - val_accuracy: 0.9565\n",
            "Epoch 132/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0178 - accuracy: 0.9951 - val_loss: 0.0721 - val_accuracy: 0.9565\n",
            "Epoch 133/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0176 - accuracy: 0.9976 - val_loss: 0.0726 - val_accuracy: 0.9565\n",
            "Epoch 134/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0175 - accuracy: 0.9976 - val_loss: 0.0720 - val_accuracy: 0.9565\n",
            "Epoch 135/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0173 - accuracy: 0.9976 - val_loss: 0.0726 - val_accuracy: 0.9565\n",
            "Epoch 136/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0171 - accuracy: 0.9951 - val_loss: 0.0730 - val_accuracy: 0.9565\n",
            "Epoch 137/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0169 - accuracy: 0.9976 - val_loss: 0.0714 - val_accuracy: 0.9565\n",
            "Epoch 138/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0167 - accuracy: 0.9976 - val_loss: 0.0719 - val_accuracy: 0.9565\n",
            "Epoch 139/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0165 - accuracy: 0.9976 - val_loss: 0.0722 - val_accuracy: 0.9565\n",
            "Epoch 140/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0164 - accuracy: 0.9976 - val_loss: 0.0716 - val_accuracy: 0.9565\n",
            "Epoch 141/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0161 - accuracy: 0.9976 - val_loss: 0.0719 - val_accuracy: 0.9565\n",
            "Epoch 142/1000\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0161 - accuracy: 0.9976 - val_loss: 0.0727 - val_accuracy: 0.9565\n",
            "Epoch 143/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0158 - accuracy: 0.9976 - val_loss: 0.0721 - val_accuracy: 0.9565\n",
            "Epoch 144/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0156 - accuracy: 0.9976 - val_loss: 0.0718 - val_accuracy: 0.9783\n",
            "Epoch 145/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0154 - accuracy: 0.9976 - val_loss: 0.0725 - val_accuracy: 0.9565\n",
            "Epoch 146/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0152 - accuracy: 0.9976 - val_loss: 0.0723 - val_accuracy: 0.9565\n",
            "Epoch 147/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0151 - accuracy: 0.9976 - val_loss: 0.0730 - val_accuracy: 0.9565\n",
            "Epoch 148/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0149 - accuracy: 0.9976 - val_loss: 0.0732 - val_accuracy: 0.9783\n",
            "Epoch 149/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0148 - accuracy: 0.9976 - val_loss: 0.0726 - val_accuracy: 0.9783\n",
            "Epoch 150/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0145 - accuracy: 0.9976 - val_loss: 0.0731 - val_accuracy: 0.9783\n",
            "Epoch 151/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0144 - accuracy: 0.9976 - val_loss: 0.0731 - val_accuracy: 0.9783\n",
            "Epoch 152/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0143 - accuracy: 0.9976 - val_loss: 0.0726 - val_accuracy: 0.9783\n",
            "Epoch 153/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0141 - accuracy: 0.9976 - val_loss: 0.0729 - val_accuracy: 0.9783\n",
            "Epoch 154/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0140 - accuracy: 0.9976 - val_loss: 0.0724 - val_accuracy: 0.9783\n",
            "Epoch 155/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0137 - accuracy: 0.9976 - val_loss: 0.0730 - val_accuracy: 0.9783\n",
            "Epoch 156/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0136 - accuracy: 0.9976 - val_loss: 0.0732 - val_accuracy: 0.9783\n",
            "Epoch 157/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0134 - accuracy: 0.9976 - val_loss: 0.0729 - val_accuracy: 0.9783\n",
            "Epoch 158/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0132 - accuracy: 0.9976 - val_loss: 0.0733 - val_accuracy: 0.9783\n",
            "Epoch 159/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0132 - accuracy: 0.9976 - val_loss: 0.0735 - val_accuracy: 0.9783\n",
            "Epoch 160/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0130 - accuracy: 0.9976 - val_loss: 0.0732 - val_accuracy: 0.9783\n",
            "Epoch 161/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0128 - accuracy: 0.9976 - val_loss: 0.0734 - val_accuracy: 0.9783\n",
            "Epoch 162/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0127 - accuracy: 0.9976 - val_loss: 0.0733 - val_accuracy: 0.9783\n",
            "Epoch 163/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0124 - accuracy: 0.9976 - val_loss: 0.0738 - val_accuracy: 0.9783\n",
            "Epoch 164/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0123 - accuracy: 0.9976 - val_loss: 0.0736 - val_accuracy: 0.9783\n",
            "Epoch 165/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0122 - accuracy: 0.9976 - val_loss: 0.0737 - val_accuracy: 0.9565\n",
            "Epoch 166/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0121 - accuracy: 0.9976 - val_loss: 0.0747 - val_accuracy: 0.9565\n",
            "Epoch 167/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0119 - accuracy: 0.9976 - val_loss: 0.0749 - val_accuracy: 0.9565\n",
            "Epoch 168/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0118 - accuracy: 0.9976 - val_loss: 0.0747 - val_accuracy: 0.9565\n",
            "Epoch 169/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0117 - accuracy: 0.9976 - val_loss: 0.0756 - val_accuracy: 0.9565\n",
            "Epoch 170/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0115 - accuracy: 0.9976 - val_loss: 0.0750 - val_accuracy: 0.9565\n",
            "Epoch 171/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0114 - accuracy: 0.9976 - val_loss: 0.0753 - val_accuracy: 0.9565\n",
            "Epoch 172/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0113 - accuracy: 0.9976 - val_loss: 0.0765 - val_accuracy: 0.9565\n",
            "Epoch 173/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0111 - accuracy: 0.9976 - val_loss: 0.0760 - val_accuracy: 0.9565\n",
            "Epoch 174/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0111 - accuracy: 0.9976 - val_loss: 0.0756 - val_accuracy: 0.9565\n",
            "Epoch 175/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0109 - accuracy: 0.9976 - val_loss: 0.0752 - val_accuracy: 0.9565\n",
            "Epoch 176/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0108 - accuracy: 0.9976 - val_loss: 0.0771 - val_accuracy: 0.9565\n",
            "Epoch 177/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0107 - accuracy: 0.9976 - val_loss: 0.0766 - val_accuracy: 0.9565\n",
            "Epoch 178/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0105 - accuracy: 0.9976 - val_loss: 0.0768 - val_accuracy: 0.9565\n",
            "Epoch 179/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0106 - accuracy: 0.9976 - val_loss: 0.0772 - val_accuracy: 0.9565\n",
            "Epoch 180/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0103 - accuracy: 0.9976 - val_loss: 0.0774 - val_accuracy: 0.9565\n",
            "Epoch 181/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0102 - accuracy: 0.9976 - val_loss: 0.0768 - val_accuracy: 0.9565\n",
            "Epoch 182/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0101 - accuracy: 0.9976 - val_loss: 0.0777 - val_accuracy: 0.9565\n",
            "Epoch 183/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0100 - accuracy: 0.9976 - val_loss: 0.0774 - val_accuracy: 0.9565\n",
            "Epoch 184/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.0773 - val_accuracy: 0.9565\n",
            "Epoch 185/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.0772 - val_accuracy: 0.9565\n",
            "Epoch 186/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.0785 - val_accuracy: 0.9565\n",
            "Epoch 187/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0096 - accuracy: 0.9976 - val_loss: 0.0787 - val_accuracy: 0.9565\n",
            "Epoch 188/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0094 - accuracy: 0.9976 - val_loss: 0.0784 - val_accuracy: 0.9565\n",
            "Epoch 189/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0093 - accuracy: 0.9976 - val_loss: 0.0776 - val_accuracy: 0.9565\n",
            "Epoch 190/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0092 - accuracy: 0.9976 - val_loss: 0.0780 - val_accuracy: 0.9565\n",
            "Epoch 191/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0092 - accuracy: 0.9976 - val_loss: 0.0780 - val_accuracy: 0.9565\n",
            "Epoch 192/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0090 - accuracy: 0.9976 - val_loss: 0.0784 - val_accuracy: 0.9565\n",
            "Epoch 193/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.0790 - val_accuracy: 0.9565\n",
            "Epoch 194/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.0795 - val_accuracy: 0.9565\n",
            "Epoch 195/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.0791 - val_accuracy: 0.9565\n",
            "Epoch 196/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.0782 - val_accuracy: 0.9565\n",
            "Epoch 197/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.0788 - val_accuracy: 0.9565\n",
            "Epoch 198/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.0791 - val_accuracy: 0.9565\n",
            "Epoch 199/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.0798 - val_accuracy: 0.9565\n",
            "Epoch 200/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.0793 - val_accuracy: 0.9565\n",
            "Epoch 201/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.0800 - val_accuracy: 0.9565\n",
            "Epoch 202/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.0802 - val_accuracy: 0.9565\n",
            "Epoch 203/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.0795 - val_accuracy: 0.9565\n",
            "Epoch 204/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.0802 - val_accuracy: 0.9565\n",
            "Epoch 205/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.0804 - val_accuracy: 0.9565\n",
            "Epoch 206/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.0808 - val_accuracy: 0.9565\n",
            "Epoch 207/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.0804 - val_accuracy: 0.9565\n",
            "Epoch 208/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.0809 - val_accuracy: 0.9565\n",
            "Epoch 209/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.0812 - val_accuracy: 0.9565\n",
            "Epoch 210/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.0814 - val_accuracy: 0.9565\n",
            "Epoch 211/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.0814 - val_accuracy: 0.9565\n",
            "Epoch 212/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.0812 - val_accuracy: 0.9565\n",
            "Epoch 213/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0819 - val_accuracy: 0.9565\n",
            "Epoch 214/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0825 - val_accuracy: 0.9565\n",
            "Epoch 215/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.0821 - val_accuracy: 0.9565\n",
            "Epoch 216/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0818 - val_accuracy: 0.9565\n",
            "Epoch 217/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0830 - val_accuracy: 0.9565\n",
            "Epoch 218/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0827 - val_accuracy: 0.9565\n",
            "Epoch 219/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0832 - val_accuracy: 0.9565\n",
            "Epoch 220/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0833 - val_accuracy: 0.9565\n",
            "Epoch 221/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0832 - val_accuracy: 0.9565\n",
            "Epoch 222/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0826 - val_accuracy: 0.9565\n",
            "Epoch 223/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0837 - val_accuracy: 0.9565\n",
            "Epoch 224/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0837 - val_accuracy: 0.9565\n",
            "Epoch 225/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0834 - val_accuracy: 0.9565\n",
            "Epoch 226/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0831 - val_accuracy: 0.9565\n",
            "Epoch 227/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0848 - val_accuracy: 0.9565\n",
            "Epoch 228/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0844 - val_accuracy: 0.9565\n",
            "Epoch 229/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0846 - val_accuracy: 0.9565\n",
            "Epoch 230/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0843 - val_accuracy: 0.9565\n",
            "Epoch 231/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0845 - val_accuracy: 0.9565\n",
            "Epoch 232/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0855 - val_accuracy: 0.9565\n",
            "Epoch 233/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0845 - val_accuracy: 0.9565\n",
            "Epoch 234/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0853 - val_accuracy: 0.9565\n",
            "Epoch 235/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0850 - val_accuracy: 0.9565\n",
            "Epoch 236/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9565\n",
            "Epoch 237/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0853 - val_accuracy: 0.9565\n",
            "Epoch 238/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0857 - val_accuracy: 0.9565\n",
            "Epoch 239/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0871 - val_accuracy: 0.9565\n",
            "Epoch 240/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0868 - val_accuracy: 0.9565\n",
            "Epoch 241/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0871 - val_accuracy: 0.9565\n",
            "Epoch 242/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0870 - val_accuracy: 0.9565\n",
            "Epoch 243/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0865 - val_accuracy: 0.9565\n",
            "Epoch 244/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0875 - val_accuracy: 0.9565\n",
            "Epoch 245/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0886 - val_accuracy: 0.9565\n",
            "Epoch 246/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0877 - val_accuracy: 0.9565\n",
            "Epoch 247/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0878 - val_accuracy: 0.9565\n",
            "Epoch 248/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 0.9565\n",
            "Epoch 249/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9565\n",
            "Epoch 250/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0892 - val_accuracy: 0.9565\n",
            "Epoch 251/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 0.9565\n",
            "Epoch 252/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0894 - val_accuracy: 0.9565\n",
            "Epoch 253/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0894 - val_accuracy: 0.9565\n",
            "Epoch 254/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0896 - val_accuracy: 0.9565\n",
            "Epoch 255/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0904 - val_accuracy: 0.9565\n",
            "Epoch 256/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0904 - val_accuracy: 0.9565\n",
            "Epoch 257/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0900 - val_accuracy: 0.9565\n",
            "Epoch 258/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0901 - val_accuracy: 0.9565\n",
            "Epoch 259/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0907 - val_accuracy: 0.9565\n",
            "Epoch 260/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0908 - val_accuracy: 0.9565\n",
            "Epoch 261/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0916 - val_accuracy: 0.9565\n",
            "Epoch 262/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0922 - val_accuracy: 0.9565\n",
            "Epoch 263/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0920 - val_accuracy: 0.9565\n",
            "Epoch 264/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0927 - val_accuracy: 0.9565\n",
            "Epoch 265/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0935 - val_accuracy: 0.9565\n",
            "Epoch 266/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0929 - val_accuracy: 0.9565\n",
            "Epoch 267/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0928 - val_accuracy: 0.9565\n",
            "Epoch 268/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0937 - val_accuracy: 0.9565\n",
            "Epoch 269/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0946 - val_accuracy: 0.9565\n",
            "Epoch 270/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0929 - val_accuracy: 0.9565\n",
            "Epoch 271/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0944 - val_accuracy: 0.9565\n",
            "Epoch 272/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0947 - val_accuracy: 0.9565\n",
            "Epoch 273/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0938 - val_accuracy: 0.9565\n",
            "Epoch 274/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0955 - val_accuracy: 0.9565\n",
            "Epoch 275/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0964 - val_accuracy: 0.9565\n",
            "Epoch 276/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0962 - val_accuracy: 0.9565\n",
            "Epoch 277/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0960 - val_accuracy: 0.9565\n",
            "Epoch 278/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0973 - val_accuracy: 0.9565\n",
            "Epoch 279/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0961 - val_accuracy: 0.9565\n",
            "Epoch 280/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0962 - val_accuracy: 0.9565\n",
            "Epoch 281/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0965 - val_accuracy: 0.9565\n",
            "Epoch 282/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0975 - val_accuracy: 0.9565\n",
            "Epoch 283/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0978 - val_accuracy: 0.9565\n",
            "Epoch 284/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0980 - val_accuracy: 0.9565\n",
            "Epoch 285/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0973 - val_accuracy: 0.9565\n",
            "Epoch 286/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0983 - val_accuracy: 0.9565\n",
            "Epoch 287/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0985 - val_accuracy: 0.9565\n",
            "Epoch 288/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0988 - val_accuracy: 0.9565\n",
            "Epoch 289/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0982 - val_accuracy: 0.9565\n",
            "Epoch 290/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0997 - val_accuracy: 0.9565\n",
            "Epoch 291/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0995 - val_accuracy: 0.9565\n",
            "Epoch 292/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 0.9565\n",
            "Epoch 293/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 0.9565\n",
            "Epoch 294/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 0.9565\n",
            "Epoch 295/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1021 - val_accuracy: 0.9565\n",
            "Epoch 296/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1022 - val_accuracy: 0.9565\n",
            "Epoch 297/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1016 - val_accuracy: 0.9565\n",
            "Epoch 298/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1017 - val_accuracy: 0.9565\n",
            "Epoch 299/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1017 - val_accuracy: 0.9565\n",
            "Epoch 300/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1023 - val_accuracy: 0.9565\n",
            "Epoch 301/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1031 - val_accuracy: 0.9565\n",
            "Epoch 302/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1028 - val_accuracy: 0.9565\n",
            "Epoch 303/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1032 - val_accuracy: 0.9565\n",
            "Epoch 304/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1037 - val_accuracy: 0.9565\n",
            "Epoch 305/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1041 - val_accuracy: 0.9565\n",
            "Epoch 306/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1035 - val_accuracy: 0.9565\n",
            "Epoch 307/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1038 - val_accuracy: 0.9565\n",
            "Epoch 308/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1045 - val_accuracy: 0.9565\n",
            "Epoch 309/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1052 - val_accuracy: 0.9565\n",
            "Epoch 310/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1055 - val_accuracy: 0.9565\n",
            "Epoch 311/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1068 - val_accuracy: 0.9565\n",
            "Epoch 312/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1062 - val_accuracy: 0.9565\n",
            "Epoch 313/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1065 - val_accuracy: 0.9565\n",
            "Epoch 314/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1062 - val_accuracy: 0.9565\n",
            "Epoch 315/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1076 - val_accuracy: 0.9565\n",
            "Epoch 316/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1073 - val_accuracy: 0.9565\n",
            "Epoch 317/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1071 - val_accuracy: 0.9565\n",
            "Epoch 318/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1066 - val_accuracy: 0.9565\n",
            "Epoch 319/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1069 - val_accuracy: 0.9565\n",
            "Epoch 320/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1074 - val_accuracy: 0.9565\n",
            "Epoch 321/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1082 - val_accuracy: 0.9565\n",
            "Epoch 322/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1080 - val_accuracy: 0.9565\n",
            "Epoch 323/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1080 - val_accuracy: 0.9565\n",
            "Epoch 324/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1087 - val_accuracy: 0.9565\n",
            "Epoch 325/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1087 - val_accuracy: 0.9565\n",
            "Epoch 326/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1089 - val_accuracy: 0.9565\n",
            "Epoch 327/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1097 - val_accuracy: 0.9565\n",
            "Epoch 328/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1114 - val_accuracy: 0.9565\n",
            "Epoch 329/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1100 - val_accuracy: 0.9565\n",
            "Epoch 330/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1093 - val_accuracy: 0.9565\n",
            "Epoch 331/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1098 - val_accuracy: 0.9565\n",
            "Epoch 332/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1117 - val_accuracy: 0.9565\n",
            "Epoch 333/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1113 - val_accuracy: 0.9565\n",
            "Epoch 334/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1107 - val_accuracy: 0.9565\n",
            "Epoch 335/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1118 - val_accuracy: 0.9565\n",
            "Epoch 336/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1126 - val_accuracy: 0.9565\n",
            "Epoch 337/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1121 - val_accuracy: 0.9565\n",
            "Epoch 338/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1127 - val_accuracy: 0.9565\n",
            "Epoch 339/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1127 - val_accuracy: 0.9565\n",
            "Epoch 340/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1132 - val_accuracy: 0.9565\n",
            "Epoch 341/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1127 - val_accuracy: 0.9565\n",
            "Epoch 342/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1137 - val_accuracy: 0.9565\n",
            "Epoch 343/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1140 - val_accuracy: 0.9565\n",
            "Epoch 344/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1139 - val_accuracy: 0.9565\n",
            "Epoch 345/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1137 - val_accuracy: 0.9565\n",
            "Epoch 346/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1144 - val_accuracy: 0.9565\n",
            "Epoch 347/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1143 - val_accuracy: 0.9565\n",
            "Epoch 348/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1158 - val_accuracy: 0.9565\n",
            "Epoch 349/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1147 - val_accuracy: 0.9565\n",
            "Epoch 350/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1163 - val_accuracy: 0.9565\n",
            "Epoch 351/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1159 - val_accuracy: 0.9565\n",
            "Epoch 352/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1159 - val_accuracy: 0.9565\n",
            "Epoch 353/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1158 - val_accuracy: 0.9565\n",
            "Epoch 354/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1152 - val_accuracy: 0.9565\n",
            "Epoch 355/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1161 - val_accuracy: 0.9565\n",
            "Epoch 356/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1172 - val_accuracy: 0.9565\n",
            "Epoch 357/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1167 - val_accuracy: 0.9565\n",
            "Epoch 358/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1168 - val_accuracy: 0.9565\n",
            "Epoch 359/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1169 - val_accuracy: 0.9565\n",
            "Epoch 360/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1175 - val_accuracy: 0.9565\n",
            "Epoch 361/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1180 - val_accuracy: 0.9565\n",
            "Epoch 362/1000\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1181 - val_accuracy: 0.9565\n",
            "Epoch 363/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1185 - val_accuracy: 0.9565\n",
            "Epoch 364/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1190 - val_accuracy: 0.9565\n",
            "Epoch 365/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1179 - val_accuracy: 0.9565\n",
            "Epoch 366/1000\n",
            "13/13 [==============================] - 0s 13ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1186 - val_accuracy: 0.9565\n",
            "Epoch 367/1000\n",
            "13/13 [==============================] - 0s 12ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1188 - val_accuracy: 0.9565\n",
            "Epoch 368/1000\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1196 - val_accuracy: 0.9565\n",
            "Epoch 369/1000\n",
            "13/13 [==============================] - 0s 13ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1185 - val_accuracy: 0.9565\n",
            "Epoch 370/1000\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1197 - val_accuracy: 0.9565\n",
            "Epoch 371/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1202 - val_accuracy: 0.9565\n",
            "Epoch 372/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1206 - val_accuracy: 0.9565\n",
            "Epoch 373/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1204 - val_accuracy: 0.9565\n",
            "Epoch 374/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1205 - val_accuracy: 0.9565\n",
            "Epoch 375/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1212 - val_accuracy: 0.9565\n",
            "Epoch 376/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1214 - val_accuracy: 0.9565\n",
            "Epoch 377/1000\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1216 - val_accuracy: 0.9565\n",
            "Epoch 378/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1215 - val_accuracy: 0.9565\n",
            "Epoch 379/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1223 - val_accuracy: 0.9565\n",
            "Epoch 380/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1224 - val_accuracy: 0.9565\n",
            "Epoch 381/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1224 - val_accuracy: 0.9565\n",
            "Epoch 382/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1226 - val_accuracy: 0.9565\n",
            "Epoch 383/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1227 - val_accuracy: 0.9565\n",
            "Epoch 384/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1226 - val_accuracy: 0.9565\n",
            "Epoch 385/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1234 - val_accuracy: 0.9565\n",
            "Epoch 386/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1230 - val_accuracy: 0.9565\n",
            "Epoch 387/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1236 - val_accuracy: 0.9565\n",
            "Epoch 388/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1243 - val_accuracy: 0.9565\n",
            "Epoch 389/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1233 - val_accuracy: 0.9565\n",
            "Epoch 390/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1239 - val_accuracy: 0.9565\n",
            "Epoch 391/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1252 - val_accuracy: 0.9565\n",
            "Epoch 392/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1254 - val_accuracy: 0.9565\n",
            "Epoch 393/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1245 - val_accuracy: 0.9565\n",
            "Epoch 394/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1244 - val_accuracy: 0.9565\n",
            "Epoch 395/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1257 - val_accuracy: 0.9565\n",
            "Epoch 396/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1263 - val_accuracy: 0.9565\n",
            "Epoch 397/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1264 - val_accuracy: 0.9565\n",
            "Epoch 398/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1265 - val_accuracy: 0.9565\n",
            "Epoch 399/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1266 - val_accuracy: 0.9565\n",
            "Epoch 400/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1275 - val_accuracy: 0.9565\n",
            "Epoch 401/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1274 - val_accuracy: 0.9565\n",
            "Epoch 402/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1269 - val_accuracy: 0.9565\n",
            "Epoch 403/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1279 - val_accuracy: 0.9565\n",
            "Epoch 404/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1272 - val_accuracy: 0.9565\n",
            "Epoch 405/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1280 - val_accuracy: 0.9565\n",
            "Epoch 406/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1276 - val_accuracy: 0.9565\n",
            "Epoch 407/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1281 - val_accuracy: 0.9565\n",
            "Epoch 408/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1290 - val_accuracy: 0.9565\n",
            "Epoch 409/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 9.8940e-04 - accuracy: 1.0000 - val_loss: 0.1295 - val_accuracy: 0.9565\n",
            "Epoch 410/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 9.8481e-04 - accuracy: 1.0000 - val_loss: 0.1287 - val_accuracy: 0.9565\n",
            "Epoch 411/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.6526e-04 - accuracy: 1.0000 - val_loss: 0.1293 - val_accuracy: 0.9565\n",
            "Epoch 412/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 9.5823e-04 - accuracy: 1.0000 - val_loss: 0.1294 - val_accuracy: 0.9565\n",
            "Epoch 413/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 9.5789e-04 - accuracy: 1.0000 - val_loss: 0.1293 - val_accuracy: 0.9565\n",
            "Epoch 414/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 9.4122e-04 - accuracy: 1.0000 - val_loss: 0.1297 - val_accuracy: 0.9565\n",
            "Epoch 415/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 9.3740e-04 - accuracy: 1.0000 - val_loss: 0.1298 - val_accuracy: 0.9565\n",
            "Epoch 416/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 9.2225e-04 - accuracy: 1.0000 - val_loss: 0.1306 - val_accuracy: 0.9565\n",
            "Epoch 417/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 9.1197e-04 - accuracy: 1.0000 - val_loss: 0.1309 - val_accuracy: 0.9565\n",
            "Epoch 418/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 9.0902e-04 - accuracy: 1.0000 - val_loss: 0.1307 - val_accuracy: 0.9565\n",
            "Epoch 419/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 9.0137e-04 - accuracy: 1.0000 - val_loss: 0.1317 - val_accuracy: 0.9565\n",
            "Epoch 420/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 8.8898e-04 - accuracy: 1.0000 - val_loss: 0.1316 - val_accuracy: 0.9565\n",
            "Epoch 421/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 8.8137e-04 - accuracy: 1.0000 - val_loss: 0.1321 - val_accuracy: 0.9565\n",
            "Epoch 422/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 8.7025e-04 - accuracy: 1.0000 - val_loss: 0.1317 - val_accuracy: 0.9565\n",
            "Epoch 423/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 8.6632e-04 - accuracy: 1.0000 - val_loss: 0.1324 - val_accuracy: 0.9565\n",
            "Epoch 424/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 8.6197e-04 - accuracy: 1.0000 - val_loss: 0.1330 - val_accuracy: 0.9565\n",
            "Epoch 425/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 8.4718e-04 - accuracy: 1.0000 - val_loss: 0.1326 - val_accuracy: 0.9565\n",
            "Epoch 426/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 8.3880e-04 - accuracy: 1.0000 - val_loss: 0.1327 - val_accuracy: 0.9565\n",
            "Epoch 427/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 8.3709e-04 - accuracy: 1.0000 - val_loss: 0.1334 - val_accuracy: 0.9565\n",
            "Epoch 428/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 8.3122e-04 - accuracy: 1.0000 - val_loss: 0.1334 - val_accuracy: 0.9565\n",
            "Epoch 429/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 8.2544e-04 - accuracy: 1.0000 - val_loss: 0.1343 - val_accuracy: 0.9565\n",
            "Epoch 430/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 8.1033e-04 - accuracy: 1.0000 - val_loss: 0.1337 - val_accuracy: 0.9565\n",
            "Epoch 431/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 8.0662e-04 - accuracy: 1.0000 - val_loss: 0.1334 - val_accuracy: 0.9565\n",
            "Epoch 432/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 8.0486e-04 - accuracy: 1.0000 - val_loss: 0.1339 - val_accuracy: 0.9565\n",
            "Epoch 433/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 7.9934e-04 - accuracy: 1.0000 - val_loss: 0.1338 - val_accuracy: 0.9565\n",
            "Epoch 434/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 7.8990e-04 - accuracy: 1.0000 - val_loss: 0.1341 - val_accuracy: 0.9565\n",
            "Epoch 435/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 7.7751e-04 - accuracy: 1.0000 - val_loss: 0.1344 - val_accuracy: 0.9565\n",
            "Epoch 436/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 7.7629e-04 - accuracy: 1.0000 - val_loss: 0.1358 - val_accuracy: 0.9565\n",
            "Epoch 437/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 7.5998e-04 - accuracy: 1.0000 - val_loss: 0.1353 - val_accuracy: 0.9565\n",
            "Epoch 438/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 7.5427e-04 - accuracy: 1.0000 - val_loss: 0.1356 - val_accuracy: 0.9565\n",
            "Epoch 439/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 7.4950e-04 - accuracy: 1.0000 - val_loss: 0.1358 - val_accuracy: 0.9565\n",
            "Epoch 440/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 7.4007e-04 - accuracy: 1.0000 - val_loss: 0.1361 - val_accuracy: 0.9565\n",
            "Epoch 441/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 7.3676e-04 - accuracy: 1.0000 - val_loss: 0.1362 - val_accuracy: 0.9565\n",
            "Epoch 442/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 7.3372e-04 - accuracy: 1.0000 - val_loss: 0.1364 - val_accuracy: 0.9565\n",
            "Epoch 443/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 7.2330e-04 - accuracy: 1.0000 - val_loss: 0.1365 - val_accuracy: 0.9565\n",
            "Epoch 444/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 7.1538e-04 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.9565\n",
            "Epoch 445/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 7.1138e-04 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.9565\n",
            "Epoch 446/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 7.0340e-04 - accuracy: 1.0000 - val_loss: 0.1371 - val_accuracy: 0.9565\n",
            "Epoch 447/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 6.9870e-04 - accuracy: 1.0000 - val_loss: 0.1380 - val_accuracy: 0.9565\n",
            "Epoch 448/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 7.0051e-04 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 0.9565\n",
            "Epoch 449/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 6.9008e-04 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9565\n",
            "Epoch 450/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 6.8044e-04 - accuracy: 1.0000 - val_loss: 0.1379 - val_accuracy: 0.9565\n",
            "Epoch 451/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 6.7526e-04 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9565\n",
            "Epoch 452/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 6.7279e-04 - accuracy: 1.0000 - val_loss: 0.1384 - val_accuracy: 0.9565\n",
            "Epoch 453/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 6.6073e-04 - accuracy: 1.0000 - val_loss: 0.1390 - val_accuracy: 0.9565\n",
            "Epoch 454/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 6.6298e-04 - accuracy: 1.0000 - val_loss: 0.1397 - val_accuracy: 0.9565\n",
            "Epoch 455/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 6.5792e-04 - accuracy: 1.0000 - val_loss: 0.1389 - val_accuracy: 0.9565\n",
            "Epoch 456/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 6.5123e-04 - accuracy: 1.0000 - val_loss: 0.1393 - val_accuracy: 0.9565\n",
            "Epoch 457/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 6.4552e-04 - accuracy: 1.0000 - val_loss: 0.1399 - val_accuracy: 0.9565\n",
            "Epoch 458/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 6.4327e-04 - accuracy: 1.0000 - val_loss: 0.1399 - val_accuracy: 0.9565\n",
            "Epoch 459/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 6.2962e-04 - accuracy: 1.0000 - val_loss: 0.1395 - val_accuracy: 0.9565\n",
            "Epoch 460/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 6.2750e-04 - accuracy: 1.0000 - val_loss: 0.1408 - val_accuracy: 0.9565\n",
            "Epoch 461/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 6.1865e-04 - accuracy: 1.0000 - val_loss: 0.1403 - val_accuracy: 0.9565\n",
            "Epoch 462/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 6.1413e-04 - accuracy: 1.0000 - val_loss: 0.1402 - val_accuracy: 0.9565\n",
            "Epoch 463/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 6.0774e-04 - accuracy: 1.0000 - val_loss: 0.1412 - val_accuracy: 0.9565\n",
            "Epoch 464/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 6.0415e-04 - accuracy: 1.0000 - val_loss: 0.1413 - val_accuracy: 0.9565\n",
            "Epoch 465/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 5.9709e-04 - accuracy: 1.0000 - val_loss: 0.1416 - val_accuracy: 0.9565\n",
            "Epoch 466/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 5.9897e-04 - accuracy: 1.0000 - val_loss: 0.1420 - val_accuracy: 0.9565\n",
            "Epoch 467/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 5.9048e-04 - accuracy: 1.0000 - val_loss: 0.1424 - val_accuracy: 0.9565\n",
            "Epoch 468/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 5.8162e-04 - accuracy: 1.0000 - val_loss: 0.1426 - val_accuracy: 0.9565\n",
            "Epoch 469/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 5.7660e-04 - accuracy: 1.0000 - val_loss: 0.1421 - val_accuracy: 0.9565\n",
            "Epoch 470/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 5.7257e-04 - accuracy: 1.0000 - val_loss: 0.1423 - val_accuracy: 0.9565\n",
            "Epoch 471/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 5.6796e-04 - accuracy: 1.0000 - val_loss: 0.1427 - val_accuracy: 0.9565\n",
            "Epoch 472/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 5.6641e-04 - accuracy: 1.0000 - val_loss: 0.1424 - val_accuracy: 0.9565\n",
            "Epoch 473/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 5.5954e-04 - accuracy: 1.0000 - val_loss: 0.1429 - val_accuracy: 0.9565\n",
            "Epoch 474/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 5.5332e-04 - accuracy: 1.0000 - val_loss: 0.1426 - val_accuracy: 0.9565\n",
            "Epoch 475/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 5.5147e-04 - accuracy: 1.0000 - val_loss: 0.1431 - val_accuracy: 0.9565\n",
            "Epoch 476/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 5.4540e-04 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9565\n",
            "Epoch 477/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 5.4404e-04 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9565\n",
            "Epoch 478/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 5.3526e-04 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9565\n",
            "Epoch 479/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 5.3328e-04 - accuracy: 1.0000 - val_loss: 0.1442 - val_accuracy: 0.9565\n",
            "Epoch 480/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 5.3030e-04 - accuracy: 1.0000 - val_loss: 0.1446 - val_accuracy: 0.9565\n",
            "Epoch 481/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 5.2397e-04 - accuracy: 1.0000 - val_loss: 0.1453 - val_accuracy: 0.9565\n",
            "Epoch 482/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 5.1724e-04 - accuracy: 1.0000 - val_loss: 0.1453 - val_accuracy: 0.9565\n",
            "Epoch 483/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 5.1646e-04 - accuracy: 1.0000 - val_loss: 0.1459 - val_accuracy: 0.9565\n",
            "Epoch 484/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 5.1356e-04 - accuracy: 1.0000 - val_loss: 0.1458 - val_accuracy: 0.9565\n",
            "Epoch 485/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 5.0804e-04 - accuracy: 1.0000 - val_loss: 0.1463 - val_accuracy: 0.9565\n",
            "Epoch 486/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 5.0128e-04 - accuracy: 1.0000 - val_loss: 0.1466 - val_accuracy: 0.9565\n",
            "Epoch 487/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 4.9781e-04 - accuracy: 1.0000 - val_loss: 0.1472 - val_accuracy: 0.9565\n",
            "Epoch 488/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 4.9243e-04 - accuracy: 1.0000 - val_loss: 0.1467 - val_accuracy: 0.9565\n",
            "Epoch 489/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 4.8818e-04 - accuracy: 1.0000 - val_loss: 0.1468 - val_accuracy: 0.9565\n",
            "Epoch 490/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 4.8647e-04 - accuracy: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9565\n",
            "Epoch 491/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 4.8575e-04 - accuracy: 1.0000 - val_loss: 0.1478 - val_accuracy: 0.9565\n",
            "Epoch 492/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 4.7539e-04 - accuracy: 1.0000 - val_loss: 0.1474 - val_accuracy: 0.9565\n",
            "Epoch 493/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 4.7598e-04 - accuracy: 1.0000 - val_loss: 0.1479 - val_accuracy: 0.9565\n",
            "Epoch 494/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 4.6738e-04 - accuracy: 1.0000 - val_loss: 0.1477 - val_accuracy: 0.9565\n",
            "Epoch 495/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 4.6886e-04 - accuracy: 1.0000 - val_loss: 0.1482 - val_accuracy: 0.9565\n",
            "Epoch 496/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 4.6096e-04 - accuracy: 1.0000 - val_loss: 0.1475 - val_accuracy: 0.9565\n",
            "Epoch 497/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 4.5540e-04 - accuracy: 1.0000 - val_loss: 0.1487 - val_accuracy: 0.9565\n",
            "Epoch 498/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 4.6061e-04 - accuracy: 1.0000 - val_loss: 0.1492 - val_accuracy: 0.9565\n",
            "Epoch 499/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 4.4869e-04 - accuracy: 1.0000 - val_loss: 0.1490 - val_accuracy: 0.9565\n",
            "Epoch 500/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 4.4349e-04 - accuracy: 1.0000 - val_loss: 0.1493 - val_accuracy: 0.9565\n",
            "Epoch 501/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 4.4270e-04 - accuracy: 1.0000 - val_loss: 0.1495 - val_accuracy: 0.9565\n",
            "Epoch 502/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 4.4040e-04 - accuracy: 1.0000 - val_loss: 0.1501 - val_accuracy: 0.9565\n",
            "Epoch 503/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 4.3526e-04 - accuracy: 1.0000 - val_loss: 0.1505 - val_accuracy: 0.9565\n",
            "Epoch 504/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 4.3190e-04 - accuracy: 1.0000 - val_loss: 0.1509 - val_accuracy: 0.9565\n",
            "Epoch 505/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 4.2566e-04 - accuracy: 1.0000 - val_loss: 0.1503 - val_accuracy: 0.9565\n",
            "Epoch 506/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 4.2305e-04 - accuracy: 1.0000 - val_loss: 0.1504 - val_accuracy: 0.9565\n",
            "Epoch 507/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 4.2154e-04 - accuracy: 1.0000 - val_loss: 0.1510 - val_accuracy: 0.9565\n",
            "Epoch 508/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 4.1595e-04 - accuracy: 1.0000 - val_loss: 0.1509 - val_accuracy: 0.9565\n",
            "Epoch 509/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 4.1676e-04 - accuracy: 1.0000 - val_loss: 0.1506 - val_accuracy: 0.9565\n",
            "Epoch 510/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 4.1663e-04 - accuracy: 1.0000 - val_loss: 0.1506 - val_accuracy: 0.9565\n",
            "Epoch 511/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 4.0817e-04 - accuracy: 1.0000 - val_loss: 0.1521 - val_accuracy: 0.9565\n",
            "Epoch 512/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 4.0616e-04 - accuracy: 1.0000 - val_loss: 0.1514 - val_accuracy: 0.9565\n",
            "Epoch 513/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 3.9889e-04 - accuracy: 1.0000 - val_loss: 0.1520 - val_accuracy: 0.9565\n",
            "Epoch 514/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 3.9490e-04 - accuracy: 1.0000 - val_loss: 0.1524 - val_accuracy: 0.9565\n",
            "Epoch 515/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 3.9517e-04 - accuracy: 1.0000 - val_loss: 0.1522 - val_accuracy: 0.9565\n",
            "Epoch 516/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 3.9112e-04 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9565\n",
            "Epoch 517/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 3.8666e-04 - accuracy: 1.0000 - val_loss: 0.1529 - val_accuracy: 0.9565\n",
            "Epoch 518/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 3.8434e-04 - accuracy: 1.0000 - val_loss: 0.1527 - val_accuracy: 0.9565\n",
            "Epoch 519/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 3.8268e-04 - accuracy: 1.0000 - val_loss: 0.1535 - val_accuracy: 0.9565\n",
            "Epoch 520/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 3.8242e-04 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9565\n",
            "Epoch 521/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 3.7632e-04 - accuracy: 1.0000 - val_loss: 0.1537 - val_accuracy: 0.9565\n",
            "Epoch 522/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 3.6991e-04 - accuracy: 1.0000 - val_loss: 0.1537 - val_accuracy: 0.9565\n",
            "Epoch 523/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 3.6930e-04 - accuracy: 1.0000 - val_loss: 0.1543 - val_accuracy: 0.9565\n",
            "Epoch 524/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 3.7496e-04 - accuracy: 1.0000 - val_loss: 0.1540 - val_accuracy: 0.9565\n",
            "Epoch 525/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 3.6383e-04 - accuracy: 1.0000 - val_loss: 0.1544 - val_accuracy: 0.9565\n",
            "Epoch 526/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 3.6458e-04 - accuracy: 1.0000 - val_loss: 0.1552 - val_accuracy: 0.9565\n",
            "Epoch 527/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 3.5539e-04 - accuracy: 1.0000 - val_loss: 0.1554 - val_accuracy: 0.9565\n",
            "Epoch 528/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 3.5626e-04 - accuracy: 1.0000 - val_loss: 0.1552 - val_accuracy: 0.9565\n",
            "Epoch 529/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 3.5056e-04 - accuracy: 1.0000 - val_loss: 0.1551 - val_accuracy: 0.9565\n",
            "Epoch 530/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 3.5109e-04 - accuracy: 1.0000 - val_loss: 0.1562 - val_accuracy: 0.9565\n",
            "Epoch 531/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 3.4391e-04 - accuracy: 1.0000 - val_loss: 0.1561 - val_accuracy: 0.9565\n",
            "Epoch 532/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 3.4039e-04 - accuracy: 1.0000 - val_loss: 0.1566 - val_accuracy: 0.9565\n",
            "Epoch 533/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 3.3971e-04 - accuracy: 1.0000 - val_loss: 0.1560 - val_accuracy: 0.9565\n",
            "Epoch 534/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 3.3756e-04 - accuracy: 1.0000 - val_loss: 0.1569 - val_accuracy: 0.9565\n",
            "Epoch 535/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 3.3332e-04 - accuracy: 1.0000 - val_loss: 0.1564 - val_accuracy: 0.9565\n",
            "Epoch 536/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 3.3426e-04 - accuracy: 1.0000 - val_loss: 0.1560 - val_accuracy: 0.9565\n",
            "Epoch 537/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 3.3243e-04 - accuracy: 1.0000 - val_loss: 0.1564 - val_accuracy: 0.9565\n",
            "Epoch 538/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 3.2504e-04 - accuracy: 1.0000 - val_loss: 0.1565 - val_accuracy: 0.9565\n",
            "Epoch 539/1000\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 3.2246e-04 - accuracy: 1.0000 - val_loss: 0.1566 - val_accuracy: 0.9565\n",
            "Epoch 540/1000\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 3.1940e-04 - accuracy: 1.0000 - val_loss: 0.1566 - val_accuracy: 0.9565\n",
            "Epoch 541/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 3.2206e-04 - accuracy: 1.0000 - val_loss: 0.1582 - val_accuracy: 0.9565\n",
            "Epoch 542/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 3.1584e-04 - accuracy: 1.0000 - val_loss: 0.1587 - val_accuracy: 0.9565\n",
            "Epoch 543/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 3.1260e-04 - accuracy: 1.0000 - val_loss: 0.1588 - val_accuracy: 0.9565\n",
            "Epoch 544/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 3.0876e-04 - accuracy: 1.0000 - val_loss: 0.1589 - val_accuracy: 0.9565\n",
            "Epoch 545/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 3.1063e-04 - accuracy: 1.0000 - val_loss: 0.1600 - val_accuracy: 0.9565\n",
            "Epoch 546/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 3.0373e-04 - accuracy: 1.0000 - val_loss: 0.1597 - val_accuracy: 0.9565\n",
            "Epoch 547/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 3.0035e-04 - accuracy: 1.0000 - val_loss: 0.1587 - val_accuracy: 0.9565\n",
            "Epoch 548/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 2.9971e-04 - accuracy: 1.0000 - val_loss: 0.1593 - val_accuracy: 0.9565\n",
            "Epoch 549/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.9636e-04 - accuracy: 1.0000 - val_loss: 0.1593 - val_accuracy: 0.9565\n",
            "Epoch 550/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 2.9660e-04 - accuracy: 1.0000 - val_loss: 0.1602 - val_accuracy: 0.9565\n",
            "Epoch 551/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.9494e-04 - accuracy: 1.0000 - val_loss: 0.1601 - val_accuracy: 0.9565\n",
            "Epoch 552/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 2.9239e-04 - accuracy: 1.0000 - val_loss: 0.1591 - val_accuracy: 0.9565\n",
            "Epoch 553/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.8805e-04 - accuracy: 1.0000 - val_loss: 0.1603 - val_accuracy: 0.9565\n",
            "Epoch 554/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.8581e-04 - accuracy: 1.0000 - val_loss: 0.1601 - val_accuracy: 0.9565\n",
            "Epoch 555/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.8334e-04 - accuracy: 1.0000 - val_loss: 0.1606 - val_accuracy: 0.9565\n",
            "Epoch 556/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.8236e-04 - accuracy: 1.0000 - val_loss: 0.1605 - val_accuracy: 0.9565\n",
            "Epoch 557/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 2.7816e-04 - accuracy: 1.0000 - val_loss: 0.1616 - val_accuracy: 0.9565\n",
            "Epoch 558/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.7608e-04 - accuracy: 1.0000 - val_loss: 0.1613 - val_accuracy: 0.9565\n",
            "Epoch 559/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.7318e-04 - accuracy: 1.0000 - val_loss: 0.1612 - val_accuracy: 0.9565\n",
            "Epoch 560/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.7139e-04 - accuracy: 1.0000 - val_loss: 0.1617 - val_accuracy: 0.9565\n",
            "Epoch 561/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 2.7052e-04 - accuracy: 1.0000 - val_loss: 0.1623 - val_accuracy: 0.9565\n",
            "Epoch 562/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 2.6703e-04 - accuracy: 1.0000 - val_loss: 0.1624 - val_accuracy: 0.9565\n",
            "Epoch 563/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 2.6520e-04 - accuracy: 1.0000 - val_loss: 0.1625 - val_accuracy: 0.9565\n",
            "Epoch 564/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 2.6228e-04 - accuracy: 1.0000 - val_loss: 0.1629 - val_accuracy: 0.9565\n",
            "Epoch 565/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 2.6020e-04 - accuracy: 1.0000 - val_loss: 0.1630 - val_accuracy: 0.9565\n",
            "Epoch 566/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 2.5897e-04 - accuracy: 1.0000 - val_loss: 0.1636 - val_accuracy: 0.9565\n",
            "Epoch 567/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 2.5721e-04 - accuracy: 1.0000 - val_loss: 0.1636 - val_accuracy: 0.9565\n",
            "Epoch 568/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 2.5356e-04 - accuracy: 1.0000 - val_loss: 0.1639 - val_accuracy: 0.9565\n",
            "Epoch 569/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 2.5271e-04 - accuracy: 1.0000 - val_loss: 0.1638 - val_accuracy: 0.9565\n",
            "Epoch 570/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.4946e-04 - accuracy: 1.0000 - val_loss: 0.1640 - val_accuracy: 0.9565\n",
            "Epoch 571/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 2.4878e-04 - accuracy: 1.0000 - val_loss: 0.1642 - val_accuracy: 0.9565\n",
            "Epoch 572/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.4532e-04 - accuracy: 1.0000 - val_loss: 0.1643 - val_accuracy: 0.9565\n",
            "Epoch 573/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.4450e-04 - accuracy: 1.0000 - val_loss: 0.1652 - val_accuracy: 0.9565\n",
            "Epoch 574/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.4471e-04 - accuracy: 1.0000 - val_loss: 0.1646 - val_accuracy: 0.9565\n",
            "Epoch 575/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.4326e-04 - accuracy: 1.0000 - val_loss: 0.1657 - val_accuracy: 0.9565\n",
            "Epoch 576/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 2.3954e-04 - accuracy: 1.0000 - val_loss: 0.1660 - val_accuracy: 0.9565\n",
            "Epoch 577/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.3845e-04 - accuracy: 1.0000 - val_loss: 0.1648 - val_accuracy: 0.9565\n",
            "Epoch 578/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 2.3523e-04 - accuracy: 1.0000 - val_loss: 0.1658 - val_accuracy: 0.9565\n",
            "Epoch 579/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.3227e-04 - accuracy: 1.0000 - val_loss: 0.1661 - val_accuracy: 0.9565\n",
            "Epoch 580/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 2.3160e-04 - accuracy: 1.0000 - val_loss: 0.1657 - val_accuracy: 0.9565\n",
            "Epoch 581/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 2.2862e-04 - accuracy: 1.0000 - val_loss: 0.1665 - val_accuracy: 0.9565\n",
            "Epoch 582/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.2781e-04 - accuracy: 1.0000 - val_loss: 0.1669 - val_accuracy: 0.9565\n",
            "Epoch 583/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.2557e-04 - accuracy: 1.0000 - val_loss: 0.1672 - val_accuracy: 0.9565\n",
            "Epoch 584/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.2449e-04 - accuracy: 1.0000 - val_loss: 0.1674 - val_accuracy: 0.9565\n",
            "Epoch 585/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.2220e-04 - accuracy: 1.0000 - val_loss: 0.1682 - val_accuracy: 0.9565\n",
            "Epoch 586/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 2.2032e-04 - accuracy: 1.0000 - val_loss: 0.1679 - val_accuracy: 0.9565\n",
            "Epoch 587/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.1745e-04 - accuracy: 1.0000 - val_loss: 0.1678 - val_accuracy: 0.9565\n",
            "Epoch 588/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.1999e-04 - accuracy: 1.0000 - val_loss: 0.1682 - val_accuracy: 0.9565\n",
            "Epoch 589/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.1441e-04 - accuracy: 1.0000 - val_loss: 0.1681 - val_accuracy: 0.9565\n",
            "Epoch 590/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.1293e-04 - accuracy: 1.0000 - val_loss: 0.1684 - val_accuracy: 0.9565\n",
            "Epoch 591/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 2.1073e-04 - accuracy: 1.0000 - val_loss: 0.1685 - val_accuracy: 0.9565\n",
            "Epoch 592/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 2.0916e-04 - accuracy: 1.0000 - val_loss: 0.1687 - val_accuracy: 0.9565\n",
            "Epoch 593/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.0934e-04 - accuracy: 1.0000 - val_loss: 0.1689 - val_accuracy: 0.9565\n",
            "Epoch 594/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.0684e-04 - accuracy: 1.0000 - val_loss: 0.1686 - val_accuracy: 0.9565\n",
            "Epoch 595/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.0458e-04 - accuracy: 1.0000 - val_loss: 0.1693 - val_accuracy: 0.9565\n",
            "Epoch 596/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.0364e-04 - accuracy: 1.0000 - val_loss: 0.1699 - val_accuracy: 0.9565\n",
            "Epoch 597/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 2.0054e-04 - accuracy: 1.0000 - val_loss: 0.1702 - val_accuracy: 0.9565\n",
            "Epoch 598/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 2.0016e-04 - accuracy: 1.0000 - val_loss: 0.1707 - val_accuracy: 0.9565\n",
            "Epoch 599/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.9752e-04 - accuracy: 1.0000 - val_loss: 0.1700 - val_accuracy: 0.9565\n",
            "Epoch 600/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.9734e-04 - accuracy: 1.0000 - val_loss: 0.1705 - val_accuracy: 0.9565\n",
            "Epoch 601/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.9692e-04 - accuracy: 1.0000 - val_loss: 0.1704 - val_accuracy: 0.9565\n",
            "Epoch 602/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.9346e-04 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 0.9565\n",
            "Epoch 603/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.9235e-04 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 0.9565\n",
            "Epoch 604/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.9055e-04 - accuracy: 1.0000 - val_loss: 0.1716 - val_accuracy: 0.9565\n",
            "Epoch 605/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.8833e-04 - accuracy: 1.0000 - val_loss: 0.1718 - val_accuracy: 0.9565\n",
            "Epoch 606/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.8878e-04 - accuracy: 1.0000 - val_loss: 0.1722 - val_accuracy: 0.9565\n",
            "Epoch 607/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.8584e-04 - accuracy: 1.0000 - val_loss: 0.1719 - val_accuracy: 0.9565\n",
            "Epoch 608/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.8493e-04 - accuracy: 1.0000 - val_loss: 0.1726 - val_accuracy: 0.9565\n",
            "Epoch 609/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.8395e-04 - accuracy: 1.0000 - val_loss: 0.1734 - val_accuracy: 0.9565\n",
            "Epoch 610/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.8339e-04 - accuracy: 1.0000 - val_loss: 0.1734 - val_accuracy: 0.9565\n",
            "Epoch 611/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.8029e-04 - accuracy: 1.0000 - val_loss: 0.1724 - val_accuracy: 0.9565\n",
            "Epoch 612/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.8048e-04 - accuracy: 1.0000 - val_loss: 0.1728 - val_accuracy: 0.9565\n",
            "Epoch 613/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.7840e-04 - accuracy: 1.0000 - val_loss: 0.1731 - val_accuracy: 0.9565\n",
            "Epoch 614/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.7693e-04 - accuracy: 1.0000 - val_loss: 0.1735 - val_accuracy: 0.9565\n",
            "Epoch 615/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.7506e-04 - accuracy: 1.0000 - val_loss: 0.1741 - val_accuracy: 0.9565\n",
            "Epoch 616/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.7317e-04 - accuracy: 1.0000 - val_loss: 0.1740 - val_accuracy: 0.9565\n",
            "Epoch 617/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 1.7333e-04 - accuracy: 1.0000 - val_loss: 0.1735 - val_accuracy: 0.9565\n",
            "Epoch 618/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 1.7421e-04 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 0.9565\n",
            "Epoch 619/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.7005e-04 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 0.9565\n",
            "Epoch 620/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.6825e-04 - accuracy: 1.0000 - val_loss: 0.1751 - val_accuracy: 0.9565\n",
            "Epoch 621/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.6867e-04 - accuracy: 1.0000 - val_loss: 0.1753 - val_accuracy: 0.9565\n",
            "Epoch 622/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.6561e-04 - accuracy: 1.0000 - val_loss: 0.1747 - val_accuracy: 0.9565\n",
            "Epoch 623/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.6563e-04 - accuracy: 1.0000 - val_loss: 0.1755 - val_accuracy: 0.9565\n",
            "Epoch 624/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.6226e-04 - accuracy: 1.0000 - val_loss: 0.1760 - val_accuracy: 0.9565\n",
            "Epoch 625/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.6192e-04 - accuracy: 1.0000 - val_loss: 0.1752 - val_accuracy: 0.9565\n",
            "Epoch 626/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.5990e-04 - accuracy: 1.0000 - val_loss: 0.1755 - val_accuracy: 0.9565\n",
            "Epoch 627/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.5890e-04 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 0.9565\n",
            "Epoch 628/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.5819e-04 - accuracy: 1.0000 - val_loss: 0.1763 - val_accuracy: 0.9565\n",
            "Epoch 629/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.5600e-04 - accuracy: 1.0000 - val_loss: 0.1764 - val_accuracy: 0.9565\n",
            "Epoch 630/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.5507e-04 - accuracy: 1.0000 - val_loss: 0.1766 - val_accuracy: 0.9565\n",
            "Epoch 631/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.5352e-04 - accuracy: 1.0000 - val_loss: 0.1772 - val_accuracy: 0.9565\n",
            "Epoch 632/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.5432e-04 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9565\n",
            "Epoch 633/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.5348e-04 - accuracy: 1.0000 - val_loss: 0.1773 - val_accuracy: 0.9565\n",
            "Epoch 634/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.5162e-04 - accuracy: 1.0000 - val_loss: 0.1774 - val_accuracy: 0.9565\n",
            "Epoch 635/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.4970e-04 - accuracy: 1.0000 - val_loss: 0.1782 - val_accuracy: 0.9565\n",
            "Epoch 636/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.4775e-04 - accuracy: 1.0000 - val_loss: 0.1777 - val_accuracy: 0.9565\n",
            "Epoch 637/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.4773e-04 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 0.9565\n",
            "Epoch 638/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.4545e-04 - accuracy: 1.0000 - val_loss: 0.1796 - val_accuracy: 0.9565\n",
            "Epoch 639/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.4462e-04 - accuracy: 1.0000 - val_loss: 0.1781 - val_accuracy: 0.9565\n",
            "Epoch 640/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.4343e-04 - accuracy: 1.0000 - val_loss: 0.1787 - val_accuracy: 0.9565\n",
            "Epoch 641/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.4207e-04 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 0.9565\n",
            "Epoch 642/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.4177e-04 - accuracy: 1.0000 - val_loss: 0.1796 - val_accuracy: 0.9565\n",
            "Epoch 643/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.3948e-04 - accuracy: 1.0000 - val_loss: 0.1793 - val_accuracy: 0.9565\n",
            "Epoch 644/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.3949e-04 - accuracy: 1.0000 - val_loss: 0.1801 - val_accuracy: 0.9565\n",
            "Epoch 645/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.3731e-04 - accuracy: 1.0000 - val_loss: 0.1802 - val_accuracy: 0.9565\n",
            "Epoch 646/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.3601e-04 - accuracy: 1.0000 - val_loss: 0.1805 - val_accuracy: 0.9565\n",
            "Epoch 647/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.3700e-04 - accuracy: 1.0000 - val_loss: 0.1807 - val_accuracy: 0.9565\n",
            "Epoch 648/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.3457e-04 - accuracy: 1.0000 - val_loss: 0.1809 - val_accuracy: 0.9565\n",
            "Epoch 649/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 1.3296e-04 - accuracy: 1.0000 - val_loss: 0.1812 - val_accuracy: 0.9565\n",
            "Epoch 650/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.3275e-04 - accuracy: 1.0000 - val_loss: 0.1812 - val_accuracy: 0.9565\n",
            "Epoch 651/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.3179e-04 - accuracy: 1.0000 - val_loss: 0.1809 - val_accuracy: 0.9565\n",
            "Epoch 652/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.3042e-04 - accuracy: 1.0000 - val_loss: 0.1821 - val_accuracy: 0.9565\n",
            "Epoch 653/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.2944e-04 - accuracy: 1.0000 - val_loss: 0.1812 - val_accuracy: 0.9565\n",
            "Epoch 654/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.2919e-04 - accuracy: 1.0000 - val_loss: 0.1815 - val_accuracy: 0.9565\n",
            "Epoch 655/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.2657e-04 - accuracy: 1.0000 - val_loss: 0.1821 - val_accuracy: 0.9565\n",
            "Epoch 656/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.2730e-04 - accuracy: 1.0000 - val_loss: 0.1829 - val_accuracy: 0.9565\n",
            "Epoch 657/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.2711e-04 - accuracy: 1.0000 - val_loss: 0.1825 - val_accuracy: 0.9565\n",
            "Epoch 658/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.2460e-04 - accuracy: 1.0000 - val_loss: 0.1834 - val_accuracy: 0.9565\n",
            "Epoch 659/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.2513e-04 - accuracy: 1.0000 - val_loss: 0.1833 - val_accuracy: 0.9565\n",
            "Epoch 660/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.2207e-04 - accuracy: 1.0000 - val_loss: 0.1833 - val_accuracy: 0.9565\n",
            "Epoch 661/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.2213e-04 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 0.9565\n",
            "Epoch 662/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.2124e-04 - accuracy: 1.0000 - val_loss: 0.1842 - val_accuracy: 0.9565\n",
            "Epoch 663/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.1959e-04 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 0.9565\n",
            "Epoch 664/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.2037e-04 - accuracy: 1.0000 - val_loss: 0.1842 - val_accuracy: 0.9565\n",
            "Epoch 665/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.1876e-04 - accuracy: 1.0000 - val_loss: 0.1847 - val_accuracy: 0.9565\n",
            "Epoch 666/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.1612e-04 - accuracy: 1.0000 - val_loss: 0.1855 - val_accuracy: 0.9565\n",
            "Epoch 667/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.1629e-04 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 0.9565\n",
            "Epoch 668/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.1516e-04 - accuracy: 1.0000 - val_loss: 0.1859 - val_accuracy: 0.9565\n",
            "Epoch 669/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 1.1448e-04 - accuracy: 1.0000 - val_loss: 0.1854 - val_accuracy: 0.9565\n",
            "Epoch 670/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.1379e-04 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 0.9565\n",
            "Epoch 671/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.1271e-04 - accuracy: 1.0000 - val_loss: 0.1858 - val_accuracy: 0.9565\n",
            "Epoch 672/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.1118e-04 - accuracy: 1.0000 - val_loss: 0.1859 - val_accuracy: 0.9565\n",
            "Epoch 673/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.1066e-04 - accuracy: 1.0000 - val_loss: 0.1861 - val_accuracy: 0.9565\n",
            "Epoch 674/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.1001e-04 - accuracy: 1.0000 - val_loss: 0.1863 - val_accuracy: 0.9565\n",
            "Epoch 675/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.0912e-04 - accuracy: 1.0000 - val_loss: 0.1870 - val_accuracy: 0.9565\n",
            "Epoch 676/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.0827e-04 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9565\n",
            "Epoch 677/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.0837e-04 - accuracy: 1.0000 - val_loss: 0.1876 - val_accuracy: 0.9565\n",
            "Epoch 678/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.0785e-04 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.9565\n",
            "Epoch 679/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.0576e-04 - accuracy: 1.0000 - val_loss: 0.1874 - val_accuracy: 0.9565\n",
            "Epoch 680/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.0490e-04 - accuracy: 1.0000 - val_loss: 0.1878 - val_accuracy: 0.9565\n",
            "Epoch 681/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.0366e-04 - accuracy: 1.0000 - val_loss: 0.1880 - val_accuracy: 0.9565\n",
            "Epoch 682/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.0322e-04 - accuracy: 1.0000 - val_loss: 0.1880 - val_accuracy: 0.9565\n",
            "Epoch 683/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.0223e-04 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.9565\n",
            "Epoch 684/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.0086e-04 - accuracy: 1.0000 - val_loss: 0.1892 - val_accuracy: 0.9565\n",
            "Epoch 685/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.0139e-04 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 0.9565\n",
            "Epoch 686/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 9.9597e-05 - accuracy: 1.0000 - val_loss: 0.1888 - val_accuracy: 0.9565\n",
            "Epoch 687/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 9.9085e-05 - accuracy: 1.0000 - val_loss: 0.1893 - val_accuracy: 0.9565\n",
            "Epoch 688/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 9.8877e-05 - accuracy: 1.0000 - val_loss: 0.1901 - val_accuracy: 0.9565\n",
            "Epoch 689/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.8183e-05 - accuracy: 1.0000 - val_loss: 0.1900 - val_accuracy: 0.9565\n",
            "Epoch 690/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 9.6849e-05 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 0.9565\n",
            "Epoch 691/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 9.6351e-05 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9565\n",
            "Epoch 692/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 9.5159e-05 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9565\n",
            "Epoch 693/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 9.4915e-05 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 0.9565\n",
            "Epoch 694/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 9.4417e-05 - accuracy: 1.0000 - val_loss: 0.1905 - val_accuracy: 0.9565\n",
            "Epoch 695/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 9.3259e-05 - accuracy: 1.0000 - val_loss: 0.1912 - val_accuracy: 0.9565\n",
            "Epoch 696/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 9.2750e-05 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 0.9565\n",
            "Epoch 697/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 9.1706e-05 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.9565\n",
            "Epoch 698/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 9.0775e-05 - accuracy: 1.0000 - val_loss: 0.1918 - val_accuracy: 0.9565\n",
            "Epoch 699/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 9.0085e-05 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.9565\n",
            "Epoch 700/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 9.0220e-05 - accuracy: 1.0000 - val_loss: 0.1922 - val_accuracy: 0.9565\n",
            "Epoch 701/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 8.9089e-05 - accuracy: 1.0000 - val_loss: 0.1926 - val_accuracy: 0.9565\n",
            "Epoch 702/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 8.9438e-05 - accuracy: 1.0000 - val_loss: 0.1927 - val_accuracy: 0.9565\n",
            "Epoch 703/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 8.8098e-05 - accuracy: 1.0000 - val_loss: 0.1926 - val_accuracy: 0.9565\n",
            "Epoch 704/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 8.7553e-05 - accuracy: 1.0000 - val_loss: 0.1924 - val_accuracy: 0.9565\n",
            "Epoch 705/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 8.6190e-05 - accuracy: 1.0000 - val_loss: 0.1927 - val_accuracy: 0.9565\n",
            "Epoch 706/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 8.5841e-05 - accuracy: 1.0000 - val_loss: 0.1933 - val_accuracy: 0.9565\n",
            "Epoch 707/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 8.4664e-05 - accuracy: 1.0000 - val_loss: 0.1936 - val_accuracy: 0.9565\n",
            "Epoch 708/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 8.4060e-05 - accuracy: 1.0000 - val_loss: 0.1936 - val_accuracy: 0.9565\n",
            "Epoch 709/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 8.3604e-05 - accuracy: 1.0000 - val_loss: 0.1936 - val_accuracy: 0.9565\n",
            "Epoch 710/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 8.2663e-05 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9565\n",
            "Epoch 711/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 8.2624e-05 - accuracy: 1.0000 - val_loss: 0.1948 - val_accuracy: 0.9565\n",
            "Epoch 712/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 8.1623e-05 - accuracy: 1.0000 - val_loss: 0.1948 - val_accuracy: 0.9565\n",
            "Epoch 713/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 8.1369e-05 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9565\n",
            "Epoch 714/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 8.0869e-05 - accuracy: 1.0000 - val_loss: 0.1947 - val_accuracy: 0.9565\n",
            "Epoch 715/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 7.9926e-05 - accuracy: 1.0000 - val_loss: 0.1951 - val_accuracy: 0.9565\n",
            "Epoch 716/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 7.9607e-05 - accuracy: 1.0000 - val_loss: 0.1950 - val_accuracy: 0.9565\n",
            "Epoch 717/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 7.9124e-05 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.9565\n",
            "Epoch 718/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 7.7955e-05 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 0.9565\n",
            "Epoch 719/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 7.8123e-05 - accuracy: 1.0000 - val_loss: 0.1951 - val_accuracy: 0.9565\n",
            "Epoch 720/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 7.7095e-05 - accuracy: 1.0000 - val_loss: 0.1961 - val_accuracy: 0.9565\n",
            "Epoch 721/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 7.6364e-05 - accuracy: 1.0000 - val_loss: 0.1959 - val_accuracy: 0.9565\n",
            "Epoch 722/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 7.5806e-05 - accuracy: 1.0000 - val_loss: 0.1968 - val_accuracy: 0.9565\n",
            "Epoch 723/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 7.5562e-05 - accuracy: 1.0000 - val_loss: 0.1973 - val_accuracy: 0.9565\n",
            "Epoch 724/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 7.4533e-05 - accuracy: 1.0000 - val_loss: 0.1973 - val_accuracy: 0.9565\n",
            "Epoch 725/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 7.4036e-05 - accuracy: 1.0000 - val_loss: 0.1975 - val_accuracy: 0.9565\n",
            "Epoch 726/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 7.4258e-05 - accuracy: 1.0000 - val_loss: 0.1970 - val_accuracy: 0.9565\n",
            "Epoch 727/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 7.2632e-05 - accuracy: 1.0000 - val_loss: 0.1977 - val_accuracy: 0.9565\n",
            "Epoch 728/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 7.1975e-05 - accuracy: 1.0000 - val_loss: 0.1980 - val_accuracy: 0.9565\n",
            "Epoch 729/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 7.1734e-05 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.9565\n",
            "Epoch 730/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 7.1166e-05 - accuracy: 1.0000 - val_loss: 0.1987 - val_accuracy: 0.9565\n",
            "Epoch 731/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 7.0835e-05 - accuracy: 1.0000 - val_loss: 0.1989 - val_accuracy: 0.9565\n",
            "Epoch 732/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 7.0180e-05 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.9565\n",
            "Epoch 733/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 6.9334e-05 - accuracy: 1.0000 - val_loss: 0.1990 - val_accuracy: 0.9565\n",
            "Epoch 734/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 6.9117e-05 - accuracy: 1.0000 - val_loss: 0.1992 - val_accuracy: 0.9565\n",
            "Epoch 735/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 6.9054e-05 - accuracy: 1.0000 - val_loss: 0.1996 - val_accuracy: 0.9565\n",
            "Epoch 736/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 6.8138e-05 - accuracy: 1.0000 - val_loss: 0.2003 - val_accuracy: 0.9565\n",
            "Epoch 737/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 6.7329e-05 - accuracy: 1.0000 - val_loss: 0.1999 - val_accuracy: 0.9565\n",
            "Epoch 738/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 6.7125e-05 - accuracy: 1.0000 - val_loss: 0.2004 - val_accuracy: 0.9565\n",
            "Epoch 739/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 6.6618e-05 - accuracy: 1.0000 - val_loss: 0.2005 - val_accuracy: 0.9565\n",
            "Epoch 740/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 6.5938e-05 - accuracy: 1.0000 - val_loss: 0.2003 - val_accuracy: 0.9565\n",
            "Epoch 741/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 6.5423e-05 - accuracy: 1.0000 - val_loss: 0.2005 - val_accuracy: 0.9565\n",
            "Epoch 742/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 6.5284e-05 - accuracy: 1.0000 - val_loss: 0.2013 - val_accuracy: 0.9565\n",
            "Epoch 743/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 6.4500e-05 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9565\n",
            "Epoch 744/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 6.3930e-05 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9565\n",
            "Epoch 745/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 6.3573e-05 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9565\n",
            "Epoch 746/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 6.2768e-05 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 0.9565\n",
            "Epoch 747/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 6.2926e-05 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9565\n",
            "Epoch 748/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 6.2146e-05 - accuracy: 1.0000 - val_loss: 0.2030 - val_accuracy: 0.9565\n",
            "Epoch 749/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 6.1531e-05 - accuracy: 1.0000 - val_loss: 0.2028 - val_accuracy: 0.9565\n",
            "Epoch 750/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 6.1005e-05 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 0.9565\n",
            "Epoch 751/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 6.0213e-05 - accuracy: 1.0000 - val_loss: 0.2032 - val_accuracy: 0.9565\n",
            "Epoch 752/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 6.0439e-05 - accuracy: 1.0000 - val_loss: 0.2032 - val_accuracy: 0.9565\n",
            "Epoch 753/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 5.9930e-05 - accuracy: 1.0000 - val_loss: 0.2033 - val_accuracy: 0.9565\n",
            "Epoch 754/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 5.9516e-05 - accuracy: 1.0000 - val_loss: 0.2043 - val_accuracy: 0.9565\n",
            "Epoch 755/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 5.9320e-05 - accuracy: 1.0000 - val_loss: 0.2036 - val_accuracy: 0.9565\n",
            "Epoch 756/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 5.8396e-05 - accuracy: 1.0000 - val_loss: 0.2039 - val_accuracy: 0.9565\n",
            "Epoch 757/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 5.8192e-05 - accuracy: 1.0000 - val_loss: 0.2040 - val_accuracy: 0.9565\n",
            "Epoch 758/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 5.7549e-05 - accuracy: 1.0000 - val_loss: 0.2049 - val_accuracy: 0.9565\n",
            "Epoch 759/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 5.7052e-05 - accuracy: 1.0000 - val_loss: 0.2045 - val_accuracy: 0.9565\n",
            "Epoch 760/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 5.6637e-05 - accuracy: 1.0000 - val_loss: 0.2047 - val_accuracy: 0.9565\n",
            "Epoch 761/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 5.6253e-05 - accuracy: 1.0000 - val_loss: 0.2055 - val_accuracy: 0.9565\n",
            "Epoch 762/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 5.5824e-05 - accuracy: 1.0000 - val_loss: 0.2057 - val_accuracy: 0.9565\n",
            "Epoch 763/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 5.5628e-05 - accuracy: 1.0000 - val_loss: 0.2052 - val_accuracy: 0.9565\n",
            "Epoch 764/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 5.4772e-05 - accuracy: 1.0000 - val_loss: 0.2060 - val_accuracy: 0.9565\n",
            "Epoch 765/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 5.4513e-05 - accuracy: 1.0000 - val_loss: 0.2071 - val_accuracy: 0.9565\n",
            "Epoch 766/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 5.4167e-05 - accuracy: 1.0000 - val_loss: 0.2063 - val_accuracy: 0.9565\n",
            "Epoch 767/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 5.4016e-05 - accuracy: 1.0000 - val_loss: 0.2064 - val_accuracy: 0.9565\n",
            "Epoch 768/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 5.3272e-05 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.9565\n",
            "Epoch 769/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 5.2591e-05 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.9565\n",
            "Epoch 770/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 5.2506e-05 - accuracy: 1.0000 - val_loss: 0.2070 - val_accuracy: 0.9565\n",
            "Epoch 771/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 5.2290e-05 - accuracy: 1.0000 - val_loss: 0.2076 - val_accuracy: 0.9565\n",
            "Epoch 772/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 5.2249e-05 - accuracy: 1.0000 - val_loss: 0.2074 - val_accuracy: 0.9565\n",
            "Epoch 773/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 5.1663e-05 - accuracy: 1.0000 - val_loss: 0.2075 - val_accuracy: 0.9565\n",
            "Epoch 774/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 5.0754e-05 - accuracy: 1.0000 - val_loss: 0.2080 - val_accuracy: 0.9565\n",
            "Epoch 775/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 5.0280e-05 - accuracy: 1.0000 - val_loss: 0.2079 - val_accuracy: 0.9565\n",
            "Epoch 776/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 5.0114e-05 - accuracy: 1.0000 - val_loss: 0.2085 - val_accuracy: 0.9565\n",
            "Epoch 777/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 4.9689e-05 - accuracy: 1.0000 - val_loss: 0.2094 - val_accuracy: 0.9565\n",
            "Epoch 778/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 4.9260e-05 - accuracy: 1.0000 - val_loss: 0.2092 - val_accuracy: 0.9565\n",
            "Epoch 779/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 4.8861e-05 - accuracy: 1.0000 - val_loss: 0.2089 - val_accuracy: 0.9565\n",
            "Epoch 780/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 4.8560e-05 - accuracy: 1.0000 - val_loss: 0.2094 - val_accuracy: 0.9565\n",
            "Epoch 781/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 4.8083e-05 - accuracy: 1.0000 - val_loss: 0.2098 - val_accuracy: 0.9565\n",
            "Epoch 782/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 4.7786e-05 - accuracy: 1.0000 - val_loss: 0.2103 - val_accuracy: 0.9565\n",
            "Epoch 783/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 4.7420e-05 - accuracy: 1.0000 - val_loss: 0.2101 - val_accuracy: 0.9565\n",
            "Epoch 784/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 4.7046e-05 - accuracy: 1.0000 - val_loss: 0.2102 - val_accuracy: 0.9565\n",
            "Epoch 785/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 4.6957e-05 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9565\n",
            "Epoch 786/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 4.6269e-05 - accuracy: 1.0000 - val_loss: 0.2112 - val_accuracy: 0.9565\n",
            "Epoch 787/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 4.6115e-05 - accuracy: 1.0000 - val_loss: 0.2106 - val_accuracy: 0.9565\n",
            "Epoch 788/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 4.5910e-05 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9565\n",
            "Epoch 789/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 4.6056e-05 - accuracy: 1.0000 - val_loss: 0.2122 - val_accuracy: 0.9565\n",
            "Epoch 790/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 4.4723e-05 - accuracy: 1.0000 - val_loss: 0.2115 - val_accuracy: 0.9565\n",
            "Epoch 791/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 4.4855e-05 - accuracy: 1.0000 - val_loss: 0.2119 - val_accuracy: 0.9565\n",
            "Epoch 792/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 4.4391e-05 - accuracy: 1.0000 - val_loss: 0.2124 - val_accuracy: 0.9565\n",
            "Epoch 793/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 4.3757e-05 - accuracy: 1.0000 - val_loss: 0.2123 - val_accuracy: 0.9565\n",
            "Epoch 794/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 4.4369e-05 - accuracy: 1.0000 - val_loss: 0.2134 - val_accuracy: 0.9565\n",
            "Epoch 795/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 4.3603e-05 - accuracy: 1.0000 - val_loss: 0.2132 - val_accuracy: 0.9565\n",
            "Epoch 796/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 4.2790e-05 - accuracy: 1.0000 - val_loss: 0.2131 - val_accuracy: 0.9565\n",
            "Epoch 797/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 4.2720e-05 - accuracy: 1.0000 - val_loss: 0.2135 - val_accuracy: 0.9565\n",
            "Epoch 798/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 4.2203e-05 - accuracy: 1.0000 - val_loss: 0.2136 - val_accuracy: 0.9565\n",
            "Epoch 799/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 4.2131e-05 - accuracy: 1.0000 - val_loss: 0.2138 - val_accuracy: 0.9565\n",
            "Epoch 800/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 4.1989e-05 - accuracy: 1.0000 - val_loss: 0.2132 - val_accuracy: 0.9565\n",
            "Epoch 801/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 4.2490e-05 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 0.9565\n",
            "Epoch 802/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 4.1209e-05 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 0.9565\n",
            "Epoch 803/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 4.0765e-05 - accuracy: 1.0000 - val_loss: 0.2148 - val_accuracy: 0.9565\n",
            "Epoch 804/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 4.0375e-05 - accuracy: 1.0000 - val_loss: 0.2143 - val_accuracy: 0.9565\n",
            "Epoch 805/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 3.9953e-05 - accuracy: 1.0000 - val_loss: 0.2144 - val_accuracy: 0.9565\n",
            "Epoch 806/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 3.9838e-05 - accuracy: 1.0000 - val_loss: 0.2152 - val_accuracy: 0.9565\n",
            "Epoch 807/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 3.9330e-05 - accuracy: 1.0000 - val_loss: 0.2156 - val_accuracy: 0.9565\n",
            "Epoch 808/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 3.9150e-05 - accuracy: 1.0000 - val_loss: 0.2159 - val_accuracy: 0.9565\n",
            "Epoch 809/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 3.8871e-05 - accuracy: 1.0000 - val_loss: 0.2156 - val_accuracy: 0.9565\n",
            "Epoch 810/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 3.8618e-05 - accuracy: 1.0000 - val_loss: 0.2156 - val_accuracy: 0.9565\n",
            "Epoch 811/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 3.8216e-05 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 0.9565\n",
            "Epoch 812/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 3.8030e-05 - accuracy: 1.0000 - val_loss: 0.2163 - val_accuracy: 0.9565\n",
            "Epoch 813/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 3.7703e-05 - accuracy: 1.0000 - val_loss: 0.2167 - val_accuracy: 0.9565\n",
            "Epoch 814/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 3.7428e-05 - accuracy: 1.0000 - val_loss: 0.2170 - val_accuracy: 0.9565\n",
            "Epoch 815/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 3.7182e-05 - accuracy: 1.0000 - val_loss: 0.2172 - val_accuracy: 0.9565\n",
            "Epoch 816/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 3.7102e-05 - accuracy: 1.0000 - val_loss: 0.2182 - val_accuracy: 0.9565\n",
            "Epoch 817/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 3.6693e-05 - accuracy: 1.0000 - val_loss: 0.2174 - val_accuracy: 0.9565\n",
            "Epoch 818/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 3.6380e-05 - accuracy: 1.0000 - val_loss: 0.2170 - val_accuracy: 0.9565\n",
            "Epoch 819/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 3.6383e-05 - accuracy: 1.0000 - val_loss: 0.2182 - val_accuracy: 0.9565\n",
            "Epoch 820/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 3.5654e-05 - accuracy: 1.0000 - val_loss: 0.2184 - val_accuracy: 0.9565\n",
            "Epoch 821/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 3.5721e-05 - accuracy: 1.0000 - val_loss: 0.2183 - val_accuracy: 0.9565\n",
            "Epoch 822/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 3.5253e-05 - accuracy: 1.0000 - val_loss: 0.2186 - val_accuracy: 0.9565\n",
            "Epoch 823/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 3.5159e-05 - accuracy: 1.0000 - val_loss: 0.2187 - val_accuracy: 0.9565\n",
            "Epoch 824/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 3.4687e-05 - accuracy: 1.0000 - val_loss: 0.2189 - val_accuracy: 0.9565\n",
            "Epoch 825/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 3.4492e-05 - accuracy: 1.0000 - val_loss: 0.2191 - val_accuracy: 0.9565\n",
            "Epoch 826/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 3.4316e-05 - accuracy: 1.0000 - val_loss: 0.2194 - val_accuracy: 0.9565\n",
            "Epoch 827/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 3.3961e-05 - accuracy: 1.0000 - val_loss: 0.2198 - val_accuracy: 0.9565\n",
            "Epoch 828/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 3.3903e-05 - accuracy: 1.0000 - val_loss: 0.2196 - val_accuracy: 0.9565\n",
            "Epoch 829/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 3.3430e-05 - accuracy: 1.0000 - val_loss: 0.2203 - val_accuracy: 0.9565\n",
            "Epoch 830/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 3.3217e-05 - accuracy: 1.0000 - val_loss: 0.2207 - val_accuracy: 0.9565\n",
            "Epoch 831/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 3.3191e-05 - accuracy: 1.0000 - val_loss: 0.2201 - val_accuracy: 0.9565\n",
            "Epoch 832/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 3.2809e-05 - accuracy: 1.0000 - val_loss: 0.2214 - val_accuracy: 0.9565\n",
            "Epoch 833/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 3.2556e-05 - accuracy: 1.0000 - val_loss: 0.2216 - val_accuracy: 0.9565\n",
            "Epoch 834/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 3.2217e-05 - accuracy: 1.0000 - val_loss: 0.2214 - val_accuracy: 0.9565\n",
            "Epoch 835/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 3.1985e-05 - accuracy: 1.0000 - val_loss: 0.2217 - val_accuracy: 0.9565\n",
            "Epoch 836/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 3.1791e-05 - accuracy: 1.0000 - val_loss: 0.2219 - val_accuracy: 0.9565\n",
            "Epoch 837/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 3.1576e-05 - accuracy: 1.0000 - val_loss: 0.2221 - val_accuracy: 0.9565\n",
            "Epoch 838/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 3.1286e-05 - accuracy: 1.0000 - val_loss: 0.2223 - val_accuracy: 0.9565\n",
            "Epoch 839/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 3.1017e-05 - accuracy: 1.0000 - val_loss: 0.2225 - val_accuracy: 0.9565\n",
            "Epoch 840/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 3.0940e-05 - accuracy: 1.0000 - val_loss: 0.2232 - val_accuracy: 0.9565\n",
            "Epoch 841/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 3.0543e-05 - accuracy: 1.0000 - val_loss: 0.2232 - val_accuracy: 0.9565\n",
            "Epoch 842/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 3.0301e-05 - accuracy: 1.0000 - val_loss: 0.2226 - val_accuracy: 0.9565\n",
            "Epoch 843/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 3.0242e-05 - accuracy: 1.0000 - val_loss: 0.2237 - val_accuracy: 0.9565\n",
            "Epoch 844/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 2.9868e-05 - accuracy: 1.0000 - val_loss: 0.2238 - val_accuracy: 0.9565\n",
            "Epoch 845/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.9749e-05 - accuracy: 1.0000 - val_loss: 0.2236 - val_accuracy: 0.9565\n",
            "Epoch 846/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 2.9435e-05 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9565\n",
            "Epoch 847/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.9181e-05 - accuracy: 1.0000 - val_loss: 0.2243 - val_accuracy: 0.9565\n",
            "Epoch 848/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.9008e-05 - accuracy: 1.0000 - val_loss: 0.2246 - val_accuracy: 0.9565\n",
            "Epoch 849/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.8904e-05 - accuracy: 1.0000 - val_loss: 0.2242 - val_accuracy: 0.9565\n",
            "Epoch 850/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 2.8404e-05 - accuracy: 1.0000 - val_loss: 0.2252 - val_accuracy: 0.9565\n",
            "Epoch 851/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.8193e-05 - accuracy: 1.0000 - val_loss: 0.2255 - val_accuracy: 0.9565\n",
            "Epoch 852/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 2.8397e-05 - accuracy: 1.0000 - val_loss: 0.2259 - val_accuracy: 0.9565\n",
            "Epoch 853/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.7938e-05 - accuracy: 1.0000 - val_loss: 0.2263 - val_accuracy: 0.9565\n",
            "Epoch 854/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.7816e-05 - accuracy: 1.0000 - val_loss: 0.2261 - val_accuracy: 0.9565\n",
            "Epoch 855/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 2.7562e-05 - accuracy: 1.0000 - val_loss: 0.2270 - val_accuracy: 0.9565\n",
            "Epoch 856/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.7439e-05 - accuracy: 1.0000 - val_loss: 0.2262 - val_accuracy: 0.9565\n",
            "Epoch 857/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.7132e-05 - accuracy: 1.0000 - val_loss: 0.2264 - val_accuracy: 0.9565\n",
            "Epoch 858/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 2.6900e-05 - accuracy: 1.0000 - val_loss: 0.2265 - val_accuracy: 0.9565\n",
            "Epoch 859/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 2.6716e-05 - accuracy: 1.0000 - val_loss: 0.2276 - val_accuracy: 0.9565\n",
            "Epoch 860/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 2.6613e-05 - accuracy: 1.0000 - val_loss: 0.2276 - val_accuracy: 0.9565\n",
            "Epoch 861/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.6527e-05 - accuracy: 1.0000 - val_loss: 0.2282 - val_accuracy: 0.9565\n",
            "Epoch 862/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.6197e-05 - accuracy: 1.0000 - val_loss: 0.2281 - val_accuracy: 0.9565\n",
            "Epoch 863/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.5835e-05 - accuracy: 1.0000 - val_loss: 0.2288 - val_accuracy: 0.9565\n",
            "Epoch 864/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.5914e-05 - accuracy: 1.0000 - val_loss: 0.2295 - val_accuracy: 0.9565\n",
            "Epoch 865/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 2.5528e-05 - accuracy: 1.0000 - val_loss: 0.2293 - val_accuracy: 0.9565\n",
            "Epoch 866/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.5301e-05 - accuracy: 1.0000 - val_loss: 0.2288 - val_accuracy: 0.9565\n",
            "Epoch 867/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 2.5399e-05 - accuracy: 1.0000 - val_loss: 0.2291 - val_accuracy: 0.9565\n",
            "Epoch 868/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 2.5102e-05 - accuracy: 1.0000 - val_loss: 0.2291 - val_accuracy: 0.9565\n",
            "Epoch 869/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.4840e-05 - accuracy: 1.0000 - val_loss: 0.2293 - val_accuracy: 0.9565\n",
            "Epoch 870/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.4602e-05 - accuracy: 1.0000 - val_loss: 0.2299 - val_accuracy: 0.9565\n",
            "Epoch 871/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 2.4398e-05 - accuracy: 1.0000 - val_loss: 0.2296 - val_accuracy: 0.9565\n",
            "Epoch 872/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 2.4122e-05 - accuracy: 1.0000 - val_loss: 0.2297 - val_accuracy: 0.9565\n",
            "Epoch 873/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.4337e-05 - accuracy: 1.0000 - val_loss: 0.2308 - val_accuracy: 0.9565\n",
            "Epoch 874/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.3887e-05 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.9565\n",
            "Epoch 875/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.3886e-05 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9565\n",
            "Epoch 876/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 2.3642e-05 - accuracy: 1.0000 - val_loss: 0.2309 - val_accuracy: 0.9565\n",
            "Epoch 877/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.3232e-05 - accuracy: 1.0000 - val_loss: 0.2319 - val_accuracy: 0.9565\n",
            "Epoch 878/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 2.3196e-05 - accuracy: 1.0000 - val_loss: 0.2318 - val_accuracy: 0.9565\n",
            "Epoch 879/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.3174e-05 - accuracy: 1.0000 - val_loss: 0.2329 - val_accuracy: 0.9565\n",
            "Epoch 880/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.2732e-05 - accuracy: 1.0000 - val_loss: 0.2331 - val_accuracy: 0.9565\n",
            "Epoch 881/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.2782e-05 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.9565\n",
            "Epoch 882/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.2642e-05 - accuracy: 1.0000 - val_loss: 0.2323 - val_accuracy: 0.9565\n",
            "Epoch 883/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.2474e-05 - accuracy: 1.0000 - val_loss: 0.2339 - val_accuracy: 0.9565\n",
            "Epoch 884/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 2.2199e-05 - accuracy: 1.0000 - val_loss: 0.2337 - val_accuracy: 0.9565\n",
            "Epoch 885/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 2.2072e-05 - accuracy: 1.0000 - val_loss: 0.2336 - val_accuracy: 0.9565\n",
            "Epoch 886/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.1786e-05 - accuracy: 1.0000 - val_loss: 0.2339 - val_accuracy: 0.9565\n",
            "Epoch 887/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.1636e-05 - accuracy: 1.0000 - val_loss: 0.2347 - val_accuracy: 0.9565\n",
            "Epoch 888/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.1569e-05 - accuracy: 1.0000 - val_loss: 0.2344 - val_accuracy: 0.9565\n",
            "Epoch 889/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.1301e-05 - accuracy: 1.0000 - val_loss: 0.2350 - val_accuracy: 0.9565\n",
            "Epoch 890/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.1462e-05 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9565\n",
            "Epoch 891/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 2.0937e-05 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9565\n",
            "Epoch 892/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.0972e-05 - accuracy: 1.0000 - val_loss: 0.2359 - val_accuracy: 0.9565\n",
            "Epoch 893/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.0707e-05 - accuracy: 1.0000 - val_loss: 0.2357 - val_accuracy: 0.9565\n",
            "Epoch 894/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.0567e-05 - accuracy: 1.0000 - val_loss: 0.2358 - val_accuracy: 0.9565\n",
            "Epoch 895/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 2.0292e-05 - accuracy: 1.0000 - val_loss: 0.2360 - val_accuracy: 0.9565\n",
            "Epoch 896/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 2.0241e-05 - accuracy: 1.0000 - val_loss: 0.2366 - val_accuracy: 0.9565\n",
            "Epoch 897/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.0068e-05 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9565\n",
            "Epoch 898/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.9960e-05 - accuracy: 1.0000 - val_loss: 0.2374 - val_accuracy: 0.9565\n",
            "Epoch 899/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.9948e-05 - accuracy: 1.0000 - val_loss: 0.2377 - val_accuracy: 0.9565\n",
            "Epoch 900/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.9787e-05 - accuracy: 1.0000 - val_loss: 0.2373 - val_accuracy: 0.9565\n",
            "Epoch 901/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.9584e-05 - accuracy: 1.0000 - val_loss: 0.2380 - val_accuracy: 0.9565\n",
            "Epoch 902/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.9471e-05 - accuracy: 1.0000 - val_loss: 0.2386 - val_accuracy: 0.9565\n",
            "Epoch 903/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.9197e-05 - accuracy: 1.0000 - val_loss: 0.2381 - val_accuracy: 0.9565\n",
            "Epoch 904/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.9168e-05 - accuracy: 1.0000 - val_loss: 0.2390 - val_accuracy: 0.9565\n",
            "Epoch 905/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.8925e-05 - accuracy: 1.0000 - val_loss: 0.2395 - val_accuracy: 0.9565\n",
            "Epoch 906/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.8953e-05 - accuracy: 1.0000 - val_loss: 0.2389 - val_accuracy: 0.9565\n",
            "Epoch 907/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.8860e-05 - accuracy: 1.0000 - val_loss: 0.2396 - val_accuracy: 0.9565\n",
            "Epoch 908/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.8540e-05 - accuracy: 1.0000 - val_loss: 0.2397 - val_accuracy: 0.9565\n",
            "Epoch 909/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.8455e-05 - accuracy: 1.0000 - val_loss: 0.2405 - val_accuracy: 0.9565\n",
            "Epoch 910/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.8218e-05 - accuracy: 1.0000 - val_loss: 0.2403 - val_accuracy: 0.9565\n",
            "Epoch 911/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.8123e-05 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9565\n",
            "Epoch 912/1000\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 1.7945e-05 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9565\n",
            "Epoch 913/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.7903e-05 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9565\n",
            "Epoch 914/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.7922e-05 - accuracy: 1.0000 - val_loss: 0.2411 - val_accuracy: 0.9565\n",
            "Epoch 915/1000\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 1.7581e-05 - accuracy: 1.0000 - val_loss: 0.2416 - val_accuracy: 0.9565\n",
            "Epoch 916/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.7585e-05 - accuracy: 1.0000 - val_loss: 0.2414 - val_accuracy: 0.9565\n",
            "Epoch 917/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.7358e-05 - accuracy: 1.0000 - val_loss: 0.2424 - val_accuracy: 0.9565\n",
            "Epoch 918/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.7168e-05 - accuracy: 1.0000 - val_loss: 0.2424 - val_accuracy: 0.9565\n",
            "Epoch 919/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 1.7233e-05 - accuracy: 1.0000 - val_loss: 0.2424 - val_accuracy: 0.9565\n",
            "Epoch 920/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.7001e-05 - accuracy: 1.0000 - val_loss: 0.2427 - val_accuracy: 0.9565\n",
            "Epoch 921/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.6860e-05 - accuracy: 1.0000 - val_loss: 0.2430 - val_accuracy: 0.9565\n",
            "Epoch 922/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.6768e-05 - accuracy: 1.0000 - val_loss: 0.2439 - val_accuracy: 0.9565\n",
            "Epoch 923/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.6579e-05 - accuracy: 1.0000 - val_loss: 0.2435 - val_accuracy: 0.9565\n",
            "Epoch 924/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.6419e-05 - accuracy: 1.0000 - val_loss: 0.2440 - val_accuracy: 0.9565\n",
            "Epoch 925/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 1.6430e-05 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9565\n",
            "Epoch 926/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.6175e-05 - accuracy: 1.0000 - val_loss: 0.2445 - val_accuracy: 0.9565\n",
            "Epoch 927/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.6190e-05 - accuracy: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.9565\n",
            "Epoch 928/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.6025e-05 - accuracy: 1.0000 - val_loss: 0.2450 - val_accuracy: 0.9565\n",
            "Epoch 929/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.5856e-05 - accuracy: 1.0000 - val_loss: 0.2453 - val_accuracy: 0.9565\n",
            "Epoch 930/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.5810e-05 - accuracy: 1.0000 - val_loss: 0.2458 - val_accuracy: 0.9565\n",
            "Epoch 931/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.5627e-05 - accuracy: 1.0000 - val_loss: 0.2456 - val_accuracy: 0.9565\n",
            "Epoch 932/1000\n",
            "13/13 [==============================] - 0s 12ms/step - loss: 1.5635e-05 - accuracy: 1.0000 - val_loss: 0.2457 - val_accuracy: 0.9565\n",
            "Epoch 933/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.5424e-05 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.9565\n",
            "Epoch 934/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.5391e-05 - accuracy: 1.0000 - val_loss: 0.2474 - val_accuracy: 0.9565\n",
            "Epoch 935/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.5333e-05 - accuracy: 1.0000 - val_loss: 0.2464 - val_accuracy: 0.9565\n",
            "Epoch 936/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.5184e-05 - accuracy: 1.0000 - val_loss: 0.2461 - val_accuracy: 0.9565\n",
            "Epoch 937/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.4926e-05 - accuracy: 1.0000 - val_loss: 0.2470 - val_accuracy: 0.9565\n",
            "Epoch 938/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.4842e-05 - accuracy: 1.0000 - val_loss: 0.2477 - val_accuracy: 0.9565\n",
            "Epoch 939/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.4729e-05 - accuracy: 1.0000 - val_loss: 0.2479 - val_accuracy: 0.9565\n",
            "Epoch 940/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.4625e-05 - accuracy: 1.0000 - val_loss: 0.2480 - val_accuracy: 0.9565\n",
            "Epoch 941/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.4476e-05 - accuracy: 1.0000 - val_loss: 0.2481 - val_accuracy: 0.9565\n",
            "Epoch 942/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.4484e-05 - accuracy: 1.0000 - val_loss: 0.2492 - val_accuracy: 0.9565\n",
            "Epoch 943/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.4333e-05 - accuracy: 1.0000 - val_loss: 0.2491 - val_accuracy: 0.9565\n",
            "Epoch 944/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 1.4166e-05 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 0.9565\n",
            "Epoch 945/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.4087e-05 - accuracy: 1.0000 - val_loss: 0.2484 - val_accuracy: 0.9565\n",
            "Epoch 946/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.3998e-05 - accuracy: 1.0000 - val_loss: 0.2490 - val_accuracy: 0.9565\n",
            "Epoch 947/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.3900e-05 - accuracy: 1.0000 - val_loss: 0.2491 - val_accuracy: 0.9565\n",
            "Epoch 948/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.3755e-05 - accuracy: 1.0000 - val_loss: 0.2494 - val_accuracy: 0.9565\n",
            "Epoch 949/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.3730e-05 - accuracy: 1.0000 - val_loss: 0.2492 - val_accuracy: 0.9565\n",
            "Epoch 950/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.3644e-05 - accuracy: 1.0000 - val_loss: 0.2500 - val_accuracy: 0.9565\n",
            "Epoch 951/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.3472e-05 - accuracy: 1.0000 - val_loss: 0.2502 - val_accuracy: 0.9565\n",
            "Epoch 952/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.3479e-05 - accuracy: 1.0000 - val_loss: 0.2505 - val_accuracy: 0.9565\n",
            "Epoch 953/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.3390e-05 - accuracy: 1.0000 - val_loss: 0.2514 - val_accuracy: 0.9565\n",
            "Epoch 954/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.3290e-05 - accuracy: 1.0000 - val_loss: 0.2510 - val_accuracy: 0.9565\n",
            "Epoch 955/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.3214e-05 - accuracy: 1.0000 - val_loss: 0.2511 - val_accuracy: 0.9565\n",
            "Epoch 956/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.3103e-05 - accuracy: 1.0000 - val_loss: 0.2517 - val_accuracy: 0.9565\n",
            "Epoch 957/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.2908e-05 - accuracy: 1.0000 - val_loss: 0.2512 - val_accuracy: 0.9565\n",
            "Epoch 958/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.2858e-05 - accuracy: 1.0000 - val_loss: 0.2518 - val_accuracy: 0.9565\n",
            "Epoch 959/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.2728e-05 - accuracy: 1.0000 - val_loss: 0.2522 - val_accuracy: 0.9565\n",
            "Epoch 960/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.2690e-05 - accuracy: 1.0000 - val_loss: 0.2519 - val_accuracy: 0.9565\n",
            "Epoch 961/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.2498e-05 - accuracy: 1.0000 - val_loss: 0.2524 - val_accuracy: 0.9565\n",
            "Epoch 962/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.2439e-05 - accuracy: 1.0000 - val_loss: 0.2532 - val_accuracy: 0.9565\n",
            "Epoch 963/1000\n",
            "13/13 [==============================] - 0s 12ms/step - loss: 1.2417e-05 - accuracy: 1.0000 - val_loss: 0.2538 - val_accuracy: 0.9565\n",
            "Epoch 964/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 1.2248e-05 - accuracy: 1.0000 - val_loss: 0.2534 - val_accuracy: 0.9565\n",
            "Epoch 965/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.2210e-05 - accuracy: 1.0000 - val_loss: 0.2531 - val_accuracy: 0.9565\n",
            "Epoch 966/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.2087e-05 - accuracy: 1.0000 - val_loss: 0.2540 - val_accuracy: 0.9565\n",
            "Epoch 967/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.2031e-05 - accuracy: 1.0000 - val_loss: 0.2538 - val_accuracy: 0.9565\n",
            "Epoch 968/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.1916e-05 - accuracy: 1.0000 - val_loss: 0.2548 - val_accuracy: 0.9565\n",
            "Epoch 969/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.1813e-05 - accuracy: 1.0000 - val_loss: 0.2547 - val_accuracy: 0.9565\n",
            "Epoch 970/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.1740e-05 - accuracy: 1.0000 - val_loss: 0.2547 - val_accuracy: 0.9565\n",
            "Epoch 971/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.1664e-05 - accuracy: 1.0000 - val_loss: 0.2549 - val_accuracy: 0.9565\n",
            "Epoch 972/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.1537e-05 - accuracy: 1.0000 - val_loss: 0.2551 - val_accuracy: 0.9565\n",
            "Epoch 973/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.1609e-05 - accuracy: 1.0000 - val_loss: 0.2559 - val_accuracy: 0.9565\n",
            "Epoch 974/1000\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 1.1395e-05 - accuracy: 1.0000 - val_loss: 0.2563 - val_accuracy: 0.9565\n",
            "Epoch 975/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.1287e-05 - accuracy: 1.0000 - val_loss: 0.2556 - val_accuracy: 0.9565\n",
            "Epoch 976/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 1.1277e-05 - accuracy: 1.0000 - val_loss: 0.2560 - val_accuracy: 0.9565\n",
            "Epoch 977/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.1111e-05 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.9565\n",
            "Epoch 978/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.1119e-05 - accuracy: 1.0000 - val_loss: 0.2563 - val_accuracy: 0.9565\n",
            "Epoch 979/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.1020e-05 - accuracy: 1.0000 - val_loss: 0.2571 - val_accuracy: 0.9565\n",
            "Epoch 980/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.0916e-05 - accuracy: 1.0000 - val_loss: 0.2575 - val_accuracy: 0.9565\n",
            "Epoch 981/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.0825e-05 - accuracy: 1.0000 - val_loss: 0.2572 - val_accuracy: 0.9565\n",
            "Epoch 982/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.0871e-05 - accuracy: 1.0000 - val_loss: 0.2578 - val_accuracy: 0.9565\n",
            "Epoch 983/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.0677e-05 - accuracy: 1.0000 - val_loss: 0.2575 - val_accuracy: 0.9565\n",
            "Epoch 984/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.0697e-05 - accuracy: 1.0000 - val_loss: 0.2583 - val_accuracy: 0.9565\n",
            "Epoch 985/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.0547e-05 - accuracy: 1.0000 - val_loss: 0.2581 - val_accuracy: 0.9565\n",
            "Epoch 986/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.0482e-05 - accuracy: 1.0000 - val_loss: 0.2580 - val_accuracy: 0.9565\n",
            "Epoch 987/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.0380e-05 - accuracy: 1.0000 - val_loss: 0.2587 - val_accuracy: 0.9565\n",
            "Epoch 988/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.0398e-05 - accuracy: 1.0000 - val_loss: 0.2595 - val_accuracy: 0.9565\n",
            "Epoch 989/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.0238e-05 - accuracy: 1.0000 - val_loss: 0.2598 - val_accuracy: 0.9565\n",
            "Epoch 990/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.0181e-05 - accuracy: 1.0000 - val_loss: 0.2597 - val_accuracy: 0.9565\n",
            "Epoch 991/1000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1.0077e-05 - accuracy: 1.0000 - val_loss: 0.2594 - val_accuracy: 0.9565\n",
            "Epoch 992/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.0003e-05 - accuracy: 1.0000 - val_loss: 0.2599 - val_accuracy: 0.9565\n",
            "Epoch 993/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 9.9029e-06 - accuracy: 1.0000 - val_loss: 0.2601 - val_accuracy: 0.9565\n",
            "Epoch 994/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 9.8656e-06 - accuracy: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.9565\n",
            "Epoch 995/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 9.7721e-06 - accuracy: 1.0000 - val_loss: 0.2608 - val_accuracy: 0.9565\n",
            "Epoch 996/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 9.7086e-06 - accuracy: 1.0000 - val_loss: 0.2613 - val_accuracy: 0.9565\n",
            "Epoch 997/1000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 9.7068e-06 - accuracy: 1.0000 - val_loss: 0.2613 - val_accuracy: 0.9565\n",
            "Epoch 998/1000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 9.5758e-06 - accuracy: 1.0000 - val_loss: 0.2609 - val_accuracy: 0.9565\n",
            "Epoch 999/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 9.5099e-06 - accuracy: 1.0000 - val_loss: 0.2618 - val_accuracy: 0.9565\n",
            "Epoch 1000/1000\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 9.4378e-06 - accuracy: 1.0000 - val_loss: 0.2625 - val_accuracy: 0.9565\n"
          ]
        }
      ],
      "source": [
        "# training the Meural Network\n",
        "\n",
        "history = model.fit(X_train_std, Y_train, validation_split=0.1, epochs=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZCz8JJ98guH"
      },
      "source": [
        "Visualizing accuracy and loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "pNism-Z55zmw"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f9fb8301840>"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "\n",
        "plt.legend(['training data', 'validation data'], loc = 'lower right')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "ZrgfNlbk9EZK"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f9fb8216800>"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "\n",
        "plt.legend(['training data', 'validation data'], loc = 'upper right')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycbLKSDl-SJX"
      },
      "source": [
        "Accuracy of the model on test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "D3RgBzQF-B8W"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3124 - accuracy: 0.9386\n",
            "0.9385964870452881\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = model.evaluate(X_test_std, Y_test)\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "OWyJPf9O-oJT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(114, 30)\n",
            "[-0.04462793 -1.41612656 -0.05903514 -0.16234067  2.0202457  -0.11323672\n",
            "  0.18500609  0.47102419  0.63336386  0.26335737  0.53209124  2.62763999\n",
            "  0.62351167  0.11405261  1.01246781  0.41126289  0.63848593  2.88971815\n",
            " -0.41675911  0.74270853 -0.32983699 -1.67435595 -0.36854552 -0.38767294\n",
            "  0.32655007 -0.74858917 -0.54689089 -0.18278004 -1.23064515 -0.6268286 ]\n"
          ]
        }
      ],
      "source": [
        "print(X_test_std.shape)\n",
        "print(X_test_std[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "XWAZk1SK-3qf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 4ms/step\n"
          ]
        }
      ],
      "source": [
        "Y_pred = model.predict(X_test_std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "umNl8qUX_GeO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(114, 2)\n",
            "[0.8295392  0.87120175]\n"
          ]
        }
      ],
      "source": [
        "print(Y_pred.shape)\n",
        "print(Y_pred[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "0lsaXHZr_mTT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-0.04462793 -1.41612656 -0.05903514 ... -0.18278004 -1.23064515\n",
            "  -0.6268286 ]\n",
            " [ 0.24583601 -0.06219797  0.21802678 ...  0.54129749  0.11047691\n",
            "   0.0483572 ]\n",
            " [-1.26115925 -0.29051645 -1.26499659 ... -1.35138617  0.269338\n",
            "  -0.28231213]\n",
            " ...\n",
            " [ 0.72709489  0.45836817  0.75277276 ...  1.46701686  1.19909344\n",
            "   0.65319961]\n",
            " [ 0.25437907  1.33054477  0.15659489 ... -1.29043534 -2.22561725\n",
            "  -1.59557344]\n",
            " [ 0.84100232 -0.06676434  0.8929529  ...  2.15137705  0.35629355\n",
            "   0.37459546]]\n"
          ]
        }
      ],
      "source": [
        "print(X_test_std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "cmaeRBc7_M59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[8.29539180e-01 8.71201754e-01]\n",
            " [5.11988960e-02 9.35544252e-01]\n",
            " [1.43051893e-05 9.99999642e-01]\n",
            " [1.00000000e+00 0.00000000e+00]\n",
            " [2.02219617e-02 9.71545637e-01]\n",
            " [1.00000000e+00 4.54679261e-25]\n",
            " [3.08215313e-05 9.99994755e-01]\n",
            " [1.92515267e-06 9.99999762e-01]\n",
            " [8.32687965e-06 9.99996185e-01]\n",
            " [9.33156286e-07 1.00000000e+00]\n",
            " [9.99870658e-01 1.51556416e-03]\n",
            " [9.42875743e-01 5.11467397e-01]\n",
            " [5.81919774e-02 9.99721706e-01]\n",
            " [1.56549551e-02 9.90875840e-01]\n",
            " [8.78652202e-07 1.00000000e+00]\n",
            " [1.00000000e+00 3.49563112e-16]\n",
            " [3.42617241e-05 9.99998808e-01]\n",
            " [1.01175509e-07 1.00000000e+00]\n",
            " [9.00517625e-05 9.99991417e-01]\n",
            " [1.00000000e+00 1.09480689e-19]\n",
            " [5.27922612e-06 9.99269783e-01]\n",
            " [1.78990064e-07 9.99999881e-01]\n",
            " [1.53713081e-05 9.99994397e-01]\n",
            " [4.96481825e-08 1.00000000e+00]\n",
            " [8.89175572e-05 9.99999285e-01]\n",
            " [1.00000000e+00 4.75020306e-19]\n",
            " [6.92681933e-04 9.98766541e-01]\n",
            " [7.36452460e-01 5.41509151e-01]\n",
            " [1.00000000e+00 2.32525367e-17]\n",
            " [1.00000000e+00 9.37324778e-19]\n",
            " [6.14446588e-03 9.99945998e-01]\n",
            " [1.36596793e-06 1.00000000e+00]\n",
            " [2.13508883e-06 9.99999762e-01]\n",
            " [1.00000000e+00 0.00000000e+00]\n",
            " [1.00000000e+00 3.03827740e-21]\n",
            " [1.09792985e-04 9.99919891e-01]\n",
            " [6.78607535e-08 9.99999046e-01]\n",
            " [1.60875745e-04 9.99056756e-01]\n",
            " [1.96320161e-06 9.99999881e-01]\n",
            " [8.74235957e-06 9.99999404e-01]\n",
            " [1.00000000e+00 6.91904125e-36]\n",
            " [1.00000000e+00 6.12633366e-09]\n",
            " [7.83848373e-06 9.99675035e-01]\n",
            " [1.10047607e-08 1.00000000e+00]\n",
            " [1.00000000e+00 2.41692266e-09]\n",
            " [8.32018998e-07 9.99999881e-01]\n",
            " [3.38654559e-07 1.00000000e+00]\n",
            " [5.08049034e-08 1.00000000e+00]\n",
            " [1.00000000e+00 6.98006881e-36]\n",
            " [1.00000000e+00 1.75176273e-16]\n",
            " [1.05027645e-07 1.00000000e+00]\n",
            " [9.99999762e-01 1.03963139e-07]\n",
            " [9.57772136e-01 3.07597607e-01]\n",
            " [6.37716539e-07 1.00000000e+00]\n",
            " [1.47522883e-07 1.00000000e+00]\n",
            " [9.98845696e-01 5.54434862e-03]\n",
            " [8.28884482e-01 8.05841208e-01]\n",
            " [1.99420855e-10 1.00000000e+00]\n",
            " [9.99979138e-01 2.06682724e-08]\n",
            " [3.16168411e-07 9.99999881e-01]\n",
            " [4.98113967e-02 9.87993240e-01]\n",
            " [9.99998450e-01 2.46068776e-10]\n",
            " [3.65171804e-09 1.00000000e+00]\n",
            " [1.00000000e+00 8.29008423e-20]\n",
            " [1.00000000e+00 4.98978300e-13]\n",
            " [6.11886207e-07 9.98738110e-01]\n",
            " [1.00000000e+00 6.99205199e-31]\n",
            " [1.00000000e+00 1.04194499e-13]\n",
            " [9.33025658e-01 7.57579446e-01]\n",
            " [1.77900530e-02 9.92341161e-01]\n",
            " [9.99975085e-01 1.03873340e-07]\n",
            " [1.00000000e+00 2.08992966e-20]\n",
            " [2.39585205e-08 1.00000000e+00]\n",
            " [1.00000000e+00 3.18620130e-10]\n",
            " [1.16136867e-07 1.00000000e+00]\n",
            " [1.00000000e+00 4.65844696e-09]\n",
            " [5.80428832e-06 9.99998689e-01]\n",
            " [1.21241214e-07 1.00000000e+00]\n",
            " [2.83812173e-03 9.99953508e-01]\n",
            " [1.00000000e+00 2.37455193e-08]\n",
            " [1.00000000e+00 5.24973023e-22]\n",
            " [1.00000000e+00 1.16196962e-10]\n",
            " [1.00000000e+00 9.49847155e-19]\n",
            " [2.56150679e-06 9.99999046e-01]\n",
            " [2.43867999e-06 9.99999642e-01]\n",
            " [6.29989356e-02 6.89406514e-01]\n",
            " [1.11033743e-11 1.00000000e+00]\n",
            " [1.85779836e-08 1.00000000e+00]\n",
            " [1.21510157e-05 9.99979258e-01]\n",
            " [1.00000000e+00 1.83018156e-24]\n",
            " [2.53597068e-06 9.99999881e-01]\n",
            " [9.63312414e-05 9.99985456e-01]\n",
            " [2.79847545e-09 1.00000000e+00]\n",
            " [1.00000000e+00 4.09352743e-18]\n",
            " [1.00000000e+00 4.06072154e-09]\n",
            " [8.68702514e-08 1.00000000e+00]\n",
            " [1.00000000e+00 1.37848749e-24]\n",
            " [1.00000000e+00 5.84320922e-18]\n",
            " [1.66424327e-02 9.62761045e-01]\n",
            " [1.70077044e-07 1.00000000e+00]\n",
            " [2.44958102e-07 1.00000000e+00]\n",
            " [9.99578655e-01 3.59417536e-05]\n",
            " [1.00000000e+00 7.66375903e-38]\n",
            " [1.00000000e+00 1.05353755e-32]\n",
            " [2.37639016e-03 9.88163948e-01]\n",
            " [5.62267921e-08 1.00000000e+00]\n",
            " [1.53914256e-10 1.00000000e+00]\n",
            " [4.78167062e-09 1.00000000e+00]\n",
            " [3.39714612e-13 1.00000000e+00]\n",
            " [3.24859493e-03 8.98638964e-01]\n",
            " [1.00000000e+00 1.44553415e-26]\n",
            " [1.00000000e+00 3.18170849e-28]\n",
            " [1.00000000e+00 4.66382772e-08]\n",
            " [1.00000000e+00 7.42898823e-16]]\n"
          ]
        }
      ],
      "source": [
        "print(Y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dx5ZqN_W_6U-"
      },
      "source": [
        "model.predict() gives the prediction probability of each class for that data point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "pPF0aJ0sAbML"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.25, 0.56]\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "#  argmax function\n",
        "\n",
        "my_list = [0.25, 0.56]\n",
        "\n",
        "index_of_max_value = np.argmax(my_list)\n",
        "print(my_list)\n",
        "print(index_of_max_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "67EUrfSf_rZi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "# converting the prediction probability to class labels\n",
        "\n",
        "Y_pred_labels = [np.argmax(i) for i in Y_pred]\n",
        "print(Y_pred_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBvyhDoEBVk8"
      },
      "source": [
        "**Building the predictive system**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "rXQi6eStBJxb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n",
            "[[7.1348068e-06 9.9999177e-01]]\n",
            "[1]\n",
            "The tumor is Benign\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/yuv/.local/lib/python3.10/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "input_data = (11.76,21.6,74.72,427.9,0.08637,0.04966,0.01657,0.01115,0.1495,0.05888,0.4062,1.21,2.635,28.47,0.005857,0.009758,0.01168,0.007445,0.02406,0.001769,12.98,25.72,82.98,516.5,0.1085,0.08615,0.05523,0.03715,0.2433,0.06563)\n",
        "\n",
        "# change the input_data to a numpy array\n",
        "input_data_as_numpy_array = np.asarray(input_data)\n",
        "\n",
        "# reshape the numpy array as we are predicting for one data point\n",
        "input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n",
        "\n",
        "# standardizing the input data\n",
        "input_data_std = scaler.transform(input_data_reshaped)\n",
        "\n",
        "prediction = model.predict(input_data_std)\n",
        "print(prediction)\n",
        "\n",
        "prediction_label = [np.argmax(prediction)]\n",
        "print(prediction_label)\n",
        "\n",
        "if(prediction_label[0] == 0):\n",
        "  print('The tumor is Malignant')\n",
        "\n",
        "else:\n",
        "  print('The tumor is Benign')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0jvu0aNDDP3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
